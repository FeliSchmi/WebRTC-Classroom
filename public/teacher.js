/******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
/******/ 		}
/******/ 	};
/******/
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = function(exports) {
/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 		}
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/
/******/ 	// create a fake namespace object
/******/ 	// mode & 1: value is a module id, require it
/******/ 	// mode & 2: merge all properties of value into the ns
/******/ 	// mode & 4: return value when already ns object
/******/ 	// mode & 8|1: behave like require
/******/ 	__webpack_require__.t = function(value, mode) {
/******/ 		if(mode & 1) value = __webpack_require__(value);
/******/ 		if(mode & 8) return value;
/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
/******/ 		var ns = Object.create(null);
/******/ 		__webpack_require__.r(ns);
/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
/******/ 		return ns;
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "";
/******/
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = "./FrontProjects/Teacher/src/main.js");
/******/ })
/************************************************************************/
/******/ ({

/***/ "./FrontProjects/Teacher/src/controllers/MainApp.js":
/*!**********************************************************!*\
  !*** ./FrontProjects/Teacher/src/controllers/MainApp.js ***!
  \**********************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _views_MainApp_html__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../views/MainApp.html */ \"./FrontProjects/Teacher/src/views/MainApp.html\");\n/* harmony import */ var _views_MainApp_html__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_views_MainApp_html__WEBPACK_IMPORTED_MODULE_0__);\n/* harmony import */ var _commons_Dialog__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../../commons/Dialog */ \"./FrontProjects/commons/Dialog.js\");\n/* harmony import */ var _commons_components_ClientList__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../../commons/components/ClientList */ \"./FrontProjects/commons/components/ClientList.js\");\n/* harmony import */ var _commons_components_MessageList__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../../commons/components/MessageList */ \"./FrontProjects/commons/components/MessageList.js\");\n/* harmony import */ var _commons_Barrage__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../../commons/Barrage */ \"./FrontProjects/commons/Barrage.js\");\n/* harmony import */ var _net_StudentConnection__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../net/StudentConnection */ \"./FrontProjects/Teacher/src/net/StudentConnection.js\");\n/* harmony import */ var multistreamsmixer__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! multistreamsmixer */ \"./node_modules/multistreamsmixer/MultiStreamsMixer.js\");\n/* harmony import */ var multistreamsmixer__WEBPACK_IMPORTED_MODULE_6___default = /*#__PURE__*/__webpack_require__.n(multistreamsmixer__WEBPACK_IMPORTED_MODULE_6__);\n/* harmony import */ var msr__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! msr */ \"./node_modules/msr/MediaStreamRecorder.js\");\n/* harmony import */ var msr__WEBPACK_IMPORTED_MODULE_7___default = /*#__PURE__*/__webpack_require__.n(msr__WEBPACK_IMPORTED_MODULE_7__);\n\n\n\n\n\n\n\n\n\nconst MainApp = Vue.component(\"main-app\", {\n    template: _views_MainApp_html__WEBPACK_IMPORTED_MODULE_0___default.a,\n    data() {\n        return {\n            classroomName: \"\",\n            username:\"\",\n            delay:10000,\n            blobCount:0,\n            finished:false,\n        }\n    },\n\n    async mounted() {\n        var camera_constraints = { audio: true, video: { width: 600/2, height: 480/2 } };\n        var constraints = { audio: true, video: { width: 1920/2, height: 1080/2 } };\n        this._localStream = await navigator.mediaDevices.getUserMedia(camera_constraints );\n        this._screenStream = await navigator.mediaDevices.getDisplayMedia(constraints);\n\n        this._screenStream.fullcanvas = true;\n        this._screenStream.width = 1920; // or 3840\n        this._screenStream.height = 1080; // or 2160 \n\n        this._localStream.width = parseInt((30 / 100) * this._screenStream.width);\n        this._localStream.height = parseInt((30 / 100) * this._screenStream.height);\n        this._localStream.top = this._screenStream.height - this._localStream.height;\n        this._localStream.left = this._screenStream.width - this._localStream.width;\n\n        let mixer = new multistreamsmixer__WEBPACK_IMPORTED_MODULE_6___default.a([this._screenStream, this._localStream]);\n\n        mixer.frameInterval = 10;\n        mixer.startDrawingFrames();\n\n        this._mixedStream = mixer.getMixedStream();\n\n        // this._localStream.getTracks().forEach(t => this._screenStream.addTrack(t));\n        // this.$refs.local_preview.srcObject = this._mixedStream;\n\n        // this._socket = io.connect('wss://xietiandi.tech', { path: '/live/socket.io'});\n        this._socket = io();\n        this._studentConnections = new Map();\n\n        localStorage.clear();\n        localStorage.socket = this._socket;\n        this.showUsernameDialog();\n        this.addSocketListeners();\n    },\n\n    methods: {\n        startRtmp() {\n            this.blobCount = 0;\n            this.finished = false;\n            this._mediaRecorder = new msr__WEBPACK_IMPORTED_MODULE_7___default.a(this._mixedStream);\n            this._mediaRecorder.mimeType = 'video/webm';\n            let self = this;\n            this._mediaRecorder.ondataavailable = function (blob) {\n                // POST/PUT \"Blob\" using FormData/XHR2\n                // self.appendBlobLink(blob);\n                let paddingCount = self.numPadding(self.blobCount++, 6)\n                let data = {\n                    recordId: paddingCount,\n                    blob: blob,\n                    finished: self.finished,\n                    room: this.classroomName\n                }\n                console.log(data);\n                self._socket.emit(\"recordBlobGot\", data);\n            };\n            this._mediaRecorder.start(this.delay);\n        },\n\n        numPadding(num, length) {\n            return (Array(length).join(\"0\") + num).slice(-length);\n        },\n\n        appendBlobLink(blob) {\n            var blobURL = URL.createObjectURL(blob);\n            var aEl = document.createElement('a');\n            aEl.appendChild(document.createTextNode(blobURL));\n            aEl.href = blobURL;\n            document.getElementById(\"header\").appendChild(aEl);\n        },\n\n        stopRtmp() {\n            this.finished = true;\n            this._mediaRecorder.stop();\n        },\n\n        sendMessage(room, content) {\n            console.log('sendmsg...' + room + \" \" + content);\n            this._socket.emit(\"msg\", room, content);\n        },\n\n        addSocketListeners() {\n            this._socket.on(\"listClients\", clients => {\n                this.$refs.client_list.setClients(clients);\n            });\n\n            this._socket.on(\"gotMsg\", (username, content) => {\n                this.$refs.message_list.gotMsg({username: username, content: content});\n                _commons_Barrage__WEBPACK_IMPORTED_MODULE_4__[\"default\"].createBarrage(username + \": \" + content);\n            });\n\n            this._socket.on(\"studentJoinedIn\", data => {\n                this._studentConnections.set(data.studentSid, new _net_StudentConnection__WEBPACK_IMPORTED_MODULE_5__[\"default\"](this._socket, data.studentSid, this._mixedStream));\n            });\n\n            this._socket.on(\"studentAnswer\", data => {\n                let sc = this._studentConnections.get(data.from);\n                if (sc) {\n                    sc.studentAnswerHandler(data);\n                }\n            });\n\n            this._socket.on(\"ice\", data => {\n                let sc = this._studentConnections.get(data.from);\n                if (sc) {\n                    sc.iceHandler(data);\n                }\n            });\n        },\n\n        showUsernameDialog() {\n            _commons_Dialog__WEBPACK_IMPORTED_MODULE_1__[\"default\"].showInput(\"请给自己起个昵称\", (name) => {\n                if (name) {\n                    this.username = name;\n                    localStorage.username = name;\n                    this.showCreateClassroomDialog();\n                } else {\n                    this.showUsernameDialog();\n                }\n            }, \"static\", false, false, \"\", \"ok\");\n        },\n\n        showCreateClassroomDialog() {\n            _commons_Dialog__WEBPACK_IMPORTED_MODULE_1__[\"default\"].showInput(\"请创建一个教室\", function (name) {\n                if (name) {\n                    let ld = _commons_Dialog__WEBPACK_IMPORTED_MODULE_1__[\"default\"].showLoading(\"正在创建教室...\");\n                    this._socket.emit(\"createClassroom\", name, this.username, function (suc) {\n                        ld.modal(\"hide\");\n                        if (suc) {\n                            this.classroomName = name;\n                            localStorage.classroomName = name;\n                            console.log(\"Joined in room\");\n                            this.$refs.local_preview.srcObject = this._mixedStream;\n                        } else {\n                            _commons_Dialog__WEBPACK_IMPORTED_MODULE_1__[\"default\"].showMessageBox(\"教室已存在，请另选其它名称\", \"提示\", function () {\n                                this.showCreateClassroomDialog();\n                            }.bind(this));\n                        }\n                    }.bind(this));\n                } else {\n                    this.showCreateClassroomDialog();\n                }\n            }.bind(this), \"static\", false, false, \"\");\n        }\n    }\n});\n\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (MainApp);\n\n\n//# sourceURL=webpack:///./FrontProjects/Teacher/src/controllers/MainApp.js?");

/***/ }),

/***/ "./FrontProjects/Teacher/src/main.js":
/*!*******************************************!*\
  !*** ./FrontProjects/Teacher/src/main.js ***!
  \*******************************************/
/*! no exports provided */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _controllers_MainApp__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./controllers/MainApp */ \"./FrontProjects/Teacher/src/controllers/MainApp.js\");\n\n\nlet rootElement = document.createElement(\"div\");\ndocument.body.appendChild(rootElement);\n\nnew _controllers_MainApp__WEBPACK_IMPORTED_MODULE_0__[\"default\"]().$mount(rootElement);\n\n//# sourceURL=webpack:///./FrontProjects/Teacher/src/main.js?");

/***/ }),

/***/ "./FrontProjects/Teacher/src/net/StudentConnection.js":
/*!************************************************************!*\
  !*** ./FrontProjects/Teacher/src/net/StudentConnection.js ***!
  \************************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\nclass StudentConnection {\n\n\n    constructor(socket, studentSid, stream) {\n        this._socket = socket;\n        this._studentSid = studentSid;\n        this._stream = stream;\n\n        this.asyncInit();\n    }\n\n    async asyncInit() {\n        let servers = {\n            'iceServers': [\n                {\n                    'url': 'stun:212.64.17.36',\n                    'username': 'kurento',\n                    'credential': 'kurento'\n                },\n                {\n                    'url': 'turn:212.64.17.36',\n                    'username': 'kurento',\n                    'credential': 'kurento'\n                }\n            ]\n        };\n        this._offerPc = new RTCPeerConnection(servers);\n\n        this._stream.getTracks().forEach(t => {\n            console.log('add track');\n            console.log(t);\n            this._offerPc.addTrack(t);\n        });\n\n        this._offerPc.onicecandidate = e => {\n            if (e.candidate) {\n                console.log('onIceCandidate...');\n                console.log(e);\n                this._socket.emit(\"ice\", {from: this._socket.id, to: this._studentSid, ice: e.candidate});\n            }\n        };\n\n        let offer = await this._offerPc.createOffer();\n        this._socket.emit(\"teacherOffer\", {from: this._socket.id, to: this._studentSid, offer: offer});\n        await this._offerPc.setLocalDescription(new RTCSessionDescription(offer));\n    }\n\n    async studentAnswerHandler(data) {\n        await this._offerPc.setRemoteDescription(new RTCSessionDescription(data.answer));\n        console.log(\"studentAnswerHandler...\");\n        console.log(data);\n    }\n\n    iceHandler(data) {\n        console.log(\"iceHandler...\");\n        console.log(data);\n        this._offerPc.addIceCandidate(new RTCIceCandidate(data.ice));\n    }\n}\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (StudentConnection);\n\n//# sourceURL=webpack:///./FrontProjects/Teacher/src/net/StudentConnection.js?");

/***/ }),

/***/ "./FrontProjects/Teacher/src/views/MainApp.html":
/*!******************************************************!*\
  !*** ./FrontProjects/Teacher/src/views/MainApp.html ***!
  \******************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = \"<div>\\n    <div class=\\\"card\\\">\\n        <div class=\\\"card-header font-weight-bold\\\" id=\\\"header\\\">\\n            教室名：{{classroomName}}, 主播：{{username}}, \\n            <buttom class=\\\"btn btn-primary\\\" v-on:click=\\\"startRtmp()\\\" > 开始推流</buttom>\\n            <buttom class=\\\"btn btn-primary\\\" v-on:click=\\\"stopRtmp()\\\" > 停止推流</buttom>\\n        </div>\\n        <div style=\\\"display: flex;flex-direction: row;\\\">\\n            <!-- <div style=\\\"display: flex;flex-direction: column;width: 220px\\\"> -->\\n                <client-list ref=\\\"client_list\\\"></client-list>\\n                <div id=\\\"barrange-div\\\" class=\\\"card\\\" style=\\\"width: 60%;\\\">\\n                    <video id=\\\"video1\\\" style=\\\"width: 100%;display: block\\\" controls autoplay ref=\\\"local_preview\\\"></video>\\n                </div>\\n                <message-list v-on:sendMessage=\\\"sendMessage\\\"  ref=\\\"message_list\\\"></message-list>\\n            <!-- </div> -->\\n        </div>\\n    </div>\\n</div>\";\n\n//# sourceURL=webpack:///./FrontProjects/Teacher/src/views/MainApp.html?");

/***/ }),

/***/ "./FrontProjects/commons/Barrage.js":
/*!******************************************!*\
  !*** ./FrontProjects/commons/Barrage.js ***!
  \******************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\nconst Barrange = {\n    // 创建一个弹幕\n    createBarrage: function(content){\n        //创建一个span\n        var barrage=document.createElement(\"span\");\n        //定义内容\n        barrage.innerText=content;\n        //指定class\n        barrage.className=\"barrage\";\n        //为弹幕设置一个随机的高度\n        barrage.style.top=this.randomNum(10,350)+'px';\n        //宽度\n        barrage.style.width=content.length*16+'px';\n        //为弹幕设置一个随机的颜色\n        barrage.style.color=this.randomColor();\n\n        barrage.style.right = '-100px';\n        //加入video中\n        document.getElementById(\"barrange-div\").appendChild(barrage);\n\n        //开始滚动\n        this.rolling(barrage)\n    },\n\n    //取随机数\n    randomNum : function (minNum,maxNum){ \n        return parseInt(Math.random()*(maxNum-minNum+1)+minNum,10); \n    } ,\n\n    //取随机颜色\n    randomColor : function(){\n        var color=\"#\";\n        for(var i=0;i<6;i++){\n            color += (Math.random()*16 | 0).toString(16);\n        }\n        return color;\n    },\n\n    //滚动弹幕\n    rolling : function (object){\n\n        //启动一个定时器，每10秒执行一次\n        var a= setInterval(function () {\n            //判断是否滚动出屏幕\n            if (object.offsetLeft> - object.innerHTML.length*16) {\n                object.style.right= object.style.right.split('p')[0]*1 + 2 + 'px';\n            }else{\n                //如果弹幕已移出屏幕，则删除本条弹幕\n                object.parentNode.removeChild(object);\n                //清理定时器\n                clearInterval(a);\n            }\n        }, 20);\n    }\n};\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (Barrange);\n\n//# sourceURL=webpack:///./FrontProjects/commons/Barrage.js?");

/***/ }),

/***/ "./FrontProjects/commons/Dialog.js":
/*!*****************************************!*\
  !*** ./FrontProjects/commons/Dialog.js ***!
  \*****************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\nconst Dialog = {\n    showInput(title, callback, backdrop = true, keyboard = true, showCloseBtn = true, cancelBtnLabel = \"取消\", okBtnLabel = \"确定\") {\n        $(`<div class=\"modal fade\" tabindex=\"-1\" role=\"dialog\" aria-labelledby=\"exampleModalLabel\" aria-hidden=\"true\">\n  <div class=\"modal-dialog\" role=\"document\">\n    <div class=\"modal-content\">\n      <div class=\"modal-header\">\n        <h5 class=\"modal-title\" id=\"exampleModalLabel\">${title}</h5>\n        ${showCloseBtn ? \"<button type=\\\"button\\\" class=\\\"close\\\" data-dismiss=\\\"modal\\\" aria-label=\\\"Close\\\"><span aria-hidden=\\\"true\\\">&times;</span></button>\" : \"\"}\n      </div>\n      <div class=\"modal-body\">\n        <input type=\"text\" class=\"message-input form-control\">\n      </div>\n      <div class=\"modal-footer\">\n        ${cancelBtnLabel ? \"<button type=\\\"button\\\" class=\\\"btn btn-secondary\\\" data-dismiss=\\\"modal\\\">\" + cancelBtnLabel + \"</button>\" : \"\"}\n        ${okBtnLabel ? \"<button type=\\\"button\\\" class=\\\"btn btn-primary\\\" data-dismiss=\\\"modal\\\">\" + okBtnLabel + \"</button>\" : \"\"}\n      </div>\n    </div>\n  </div>\n</div>`).appendTo(document.body).modal({\n            keyboard: keyboard,\n            backdrop: backdrop\n        }).on(\"hidden.bs.modal\", function () {\n            let jqThis = $(this);\n            if (callback) {\n                callback(jqThis.find(\".message-input\").val());\n            }\n            jqThis.remove();\n        });\n    },\n\n    showMessageBox(msg, title = \"\", closeCallback = null) {\n        $(`<div class=\"modal fade\" id=\"staticBackdrop\" data-backdrop=\"static\" tabindex=\"-1\" role=\"dialog\" aria-labelledby=\"staticBackdropLabel\" aria-hidden=\"true\">\n  <div class=\"modal-dialog\" role=\"document\">\n    <div class=\"modal-content\">\n      <div class=\"modal-header\">\n        <h5 class=\"modal-title\" id=\"staticBackdropLabel\">${title}</h5>\n        <button type=\"button\" class=\"close\" data-dismiss=\"modal\" aria-label=\"Close\">\n          <span aria-hidden=\"true\">&times;</span>\n        </button>\n      </div>\n      <div class=\"modal-body\">\n        ${msg}\n      </div>\n      <div class=\"modal-footer\">\n        <button type=\"button\" class=\"btn btn-primary\" data-dismiss=\"modal\">OK</button>\n      </div>\n    </div>\n  </div>\n</div>`).appendTo(document.body).modal().on(\"hidden.bs.modal\", function () {\n            $(this).remove();\n\n            if (closeCallback) {\n                closeCallback();\n            }\n        });\n    },\n\n\n    showLoading(msg) {\n        return $(`<div class=\"modal\" tabindex=\"-1\" role=\"dialog\" aria-hidden=\"true\">\n  <div class=\"modal-dialog\" role=\"document\">\n    <div class=\"modal-content\">\n      <div class=\"modal-body\">\n        ${msg}\n      </div>\n    </div>\n  </div>\n</div>`).modal({\n            keyboard: false,\n            backdrop: \"static\"\n        }).on(\"hidden.bs.modal\", function () {\n            $(this).remove();\n        });\n    }\n};\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (Dialog);\n\n//# sourceURL=webpack:///./FrontProjects/commons/Dialog.js?");

/***/ }),

/***/ "./FrontProjects/commons/components/ClientList.html":
/*!**********************************************************!*\
  !*** ./FrontProjects/commons/components/ClientList.html ***!
  \**********************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = \"<div class=\\\"card\\\" style=\\\"width: 220px; z-index: 100;\\\">\\n    <div class=\\\"card-header\\\">\\n        所有人\\n    </div>\\n    <div>\\n        <div v-for=\\\"c in clients\\\">\\n            {{c}}\\n        </div>\\n    </div>\\n</div>\";\n\n//# sourceURL=webpack:///./FrontProjects/commons/components/ClientList.html?");

/***/ }),

/***/ "./FrontProjects/commons/components/ClientList.js":
/*!********************************************************!*\
  !*** ./FrontProjects/commons/components/ClientList.js ***!
  \********************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _ClientList_html__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ClientList.html */ \"./FrontProjects/commons/components/ClientList.html\");\n/* harmony import */ var _ClientList_html__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_ClientList_html__WEBPACK_IMPORTED_MODULE_0__);\n\n\nconst ClientList = Vue.component(\"client-list\", {\n    template: _ClientList_html__WEBPACK_IMPORTED_MODULE_0___default.a,\n\n    data() {\n        return {\n            clients: []\n        };\n    },\n\n    methods: {\n        setClients(clients) {\n            this.clients.length = 0;\n            this.clients.push(...clients);\n        }\n    }\n});\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (ClientList);\n\n//# sourceURL=webpack:///./FrontProjects/commons/components/ClientList.js?");

/***/ }),

/***/ "./FrontProjects/commons/components/MessageList.html":
/*!***********************************************************!*\
  !*** ./FrontProjects/commons/components/MessageList.html ***!
  \***********************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = \"<div class=\\\"card\\\" style=\\\"width: 300px; z-index: 100;\\\">\\n    <div class=\\\"card-header\\\">\\n        对话\\n    </div>\\n    <div>\\n        <!-- <div v-for=\\\"c in messages\\\">\\n            {{c.username}} : {{c.content}}\\n        </div> -->\\n        <div>\\n            <textarea id=\\\"msgArea\\\" rows=\\\"25\\\" style=\\\"width: 100%;\\\"  readonly>{{areaMsgs}}</textarea>\\n        </div>\\n    </div>\\n    <div>\\n        <!-- <div style=\\\"position: absolute; bottom:0px\\\"> -->\\n        <div>\\n            <input type=\\\"text\\\" v-model=\\\"content\\\">\\n            <buttom class=\\\"btn btn-primary\\\" v-on:click=\\\"sendMessage()\\\" @keyup.enter=\\\"sendMessage()\\\">发送</buttom>\\n        </div>\\n    </div>\\n</div>\";\n\n//# sourceURL=webpack:///./FrontProjects/commons/components/MessageList.html?");

/***/ }),

/***/ "./FrontProjects/commons/components/MessageList.js":
/*!*********************************************************!*\
  !*** ./FrontProjects/commons/components/MessageList.js ***!
  \*********************************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _MessageList_html__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./MessageList.html */ \"./FrontProjects/commons/components/MessageList.html\");\n/* harmony import */ var _MessageList_html__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_MessageList_html__WEBPACK_IMPORTED_MODULE_0__);\n\n\nconst MessageList = Vue.component(\"message-list\", {\n    template: _MessageList_html__WEBPACK_IMPORTED_MODULE_0___default.a,\n\n    data() {\n        return {\n            messages: [{'username': \"帅天帝\", 'content': \"大家好, 欢迎来到我的直播平台。\"}],\n            username: \"\",\n            content:\"\",\n            areaMsgs: \"\"\n        };\n    },\n\n    created() {\n      this.keyupEnter();  \n    },\n\n    methods: {\n        keyupEnter(){\n            document.onkeydown = e =>{\n                let body = document.getElementsByTagName('body')[0]\n                if (e.keyCode === 13) {\n                    console.log('enter')\n                    this.sendMessage()\n                }\n            }\n        },\n\n        sendMessage() {\n            let room = localStorage.classroomName;\n            if (room && this.content) {\n                console.log('msgList send: ' + room + ' ' + this.content);\n                this.$emit('sendMessage', room, this.content);\n                this.content = \"\";\n            }\n        },\n\n        gotMsg(message) {\n            this.messages.push(message);\n            this.areaMsgs = this.areaMsgs + message.username + \": \" + message.content + \"\\n\";\n            let textarea = document.getElementById('msgArea');\n            textarea.scrollTop = textarea.scrollHeight;\n        },\n\n        listMessages(messages) {\n            this.messages.length = 0;\n            this.messages.push(...messages);\n        }\n    }\n});\n\n/* harmony default export */ __webpack_exports__[\"default\"] = (MessageList);\n\n//# sourceURL=webpack:///./FrontProjects/commons/components/MessageList.js?");

/***/ }),

/***/ "./node_modules/msr/MediaStreamRecorder.js":
/*!*************************************************!*\
  !*** ./node_modules/msr/MediaStreamRecorder.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(global) {var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;// Last time updated: 2016-07-03 8:51:35 AM UTC\n\n// links:\n// Open-Sourced: https://github.com/streamproc/MediaStreamRecorder\n// https://cdn.WebRTC-Experiment.com/MediaStreamRecorder.js\n// https://www.WebRTC-Experiment.com/MediaStreamRecorder.js\n// npm install msr\n\n//------------------------------------\n\n// Browsers Support::\n// Chrome (all versions) [ audio/video separately ]\n// Firefox ( >= 29 ) [ audio/video in single webm/mp4 container or only audio in ogg ]\n// Opera (all versions) [ same as chrome ]\n// Android (Chrome) [ only video ]\n// Android (Opera) [ only video ]\n// Android (Firefox) [ only video ]\n// Microsoft Edge (Only Audio & Gif)\n\n//------------------------------------\n// Muaz Khan     - www.MuazKhan.com\n// MIT License   - www.WebRTC-Experiment.com/licence\n//------------------------------------\n\n// ______________________\n// MediaStreamRecorder.js\n\nfunction MediaStreamRecorder(mediaStream) {\n    if (!mediaStream) {\n        throw 'MediaStream is mandatory.';\n    }\n\n    // void start(optional long timeSlice)\n    // timestamp to fire \"ondataavailable\"\n    this.start = function(timeSlice) {\n        var Recorder;\n\n        if (typeof MediaRecorder !== 'undefined') {\n            Recorder = MediaRecorderWrapper;\n        } else if (IsChrome || IsOpera || IsEdge) {\n            if (this.mimeType.indexOf('video') !== -1) {\n                Recorder = WhammyRecorder;\n            } else if (this.mimeType.indexOf('audio') !== -1) {\n                Recorder = StereoAudioRecorder;\n            }\n        }\n\n        // video recorder (in GIF format)\n        if (this.mimeType === 'image/gif') {\n            Recorder = GifRecorder;\n        }\n\n        // audio/wav is supported only via StereoAudioRecorder\n        // audio/pcm (int16) is supported only via StereoAudioRecorder\n        if (this.mimeType === 'audio/wav' || this.mimeType === 'audio/pcm') {\n            Recorder = StereoAudioRecorder;\n        }\n\n        // allows forcing StereoAudioRecorder.js on Edge/Firefox\n        if (this.recorderType) {\n            Recorder = this.recorderType;\n        }\n\n        mediaRecorder = new Recorder(mediaStream);\n        mediaRecorder.blobs = [];\n\n        var self = this;\n        mediaRecorder.ondataavailable = function(data) {\n            mediaRecorder.blobs.push(data);\n            self.ondataavailable(data);\n        };\n        mediaRecorder.onstop = this.onstop;\n        mediaRecorder.onStartedDrawingNonBlankFrames = this.onStartedDrawingNonBlankFrames;\n\n        // Merge all data-types except \"function\"\n        mediaRecorder = mergeProps(mediaRecorder, this);\n\n        mediaRecorder.start(timeSlice);\n    };\n\n    this.onStartedDrawingNonBlankFrames = function() {};\n    this.clearOldRecordedFrames = function() {\n        if (!mediaRecorder) {\n            return;\n        }\n\n        mediaRecorder.clearOldRecordedFrames();\n    };\n\n    this.stop = function() {\n        if (mediaRecorder) {\n            mediaRecorder.stop();\n        }\n    };\n\n    this.ondataavailable = function(blob) {\n        console.log('ondataavailable..', blob);\n    };\n\n    this.onstop = function(error) {\n        console.warn('stopped..', error);\n    };\n\n    this.save = function(file, fileName) {\n        if (!file) {\n            if (!mediaRecorder) {\n                return;\n            }\n\n            ConcatenateBlobs(mediaRecorder.blobs, mediaRecorder.blobs[0].type, function(concatenatedBlob) {\n                invokeSaveAsDialog(concatenatedBlob);\n            });\n            return;\n        }\n        invokeSaveAsDialog(file, fileName);\n    };\n\n    this.pause = function() {\n        if (!mediaRecorder) {\n            return;\n        }\n        mediaRecorder.pause();\n        console.log('Paused recording.', this.mimeType || mediaRecorder.mimeType);\n    };\n\n    this.resume = function() {\n        if (!mediaRecorder) {\n            return;\n        }\n        mediaRecorder.resume();\n        console.log('Resumed recording.', this.mimeType || mediaRecorder.mimeType);\n    };\n\n    // StereoAudioRecorder || WhammyRecorder || MediaRecorderWrapper || GifRecorder\n    this.recorderType = null;\n\n    // video/webm or audio/webm or audio/ogg or audio/wav\n    this.mimeType = 'video/webm';\n\n    // logs are enabled by default\n    this.disableLogs = false;\n\n    // Reference to \"MediaRecorder.js\"\n    var mediaRecorder;\n}\n\n// ______________________\n// MultiStreamRecorder.js\n\nfunction MultiStreamRecorder(mediaStream) {\n    if (!mediaStream) {\n        throw 'MediaStream is mandatory.';\n    }\n\n    var self = this;\n    var isMediaRecorder = isMediaRecorderCompatible();\n\n    this.stream = mediaStream;\n\n    // void start(optional long timeSlice)\n    // timestamp to fire \"ondataavailable\"\n    this.start = function(timeSlice) {\n        audioRecorder = new MediaStreamRecorder(mediaStream);\n        videoRecorder = new MediaStreamRecorder(mediaStream);\n\n        audioRecorder.mimeType = 'audio/ogg';\n        videoRecorder.mimeType = 'video/webm';\n\n        for (var prop in this) {\n            if (typeof this[prop] !== 'function') {\n                audioRecorder[prop] = videoRecorder[prop] = this[prop];\n            }\n        }\n\n        audioRecorder.ondataavailable = function(blob) {\n            if (!audioVideoBlobs[recordingInterval]) {\n                audioVideoBlobs[recordingInterval] = {};\n            }\n\n            audioVideoBlobs[recordingInterval].audio = blob;\n\n            if (audioVideoBlobs[recordingInterval].video && !audioVideoBlobs[recordingInterval].onDataAvailableEventFired) {\n                audioVideoBlobs[recordingInterval].onDataAvailableEventFired = true;\n                fireOnDataAvailableEvent(audioVideoBlobs[recordingInterval]);\n            }\n        };\n\n        videoRecorder.ondataavailable = function(blob) {\n            if (isMediaRecorder) {\n                return self.ondataavailable({\n                    video: blob,\n                    audio: blob\n                });\n            }\n\n            if (!audioVideoBlobs[recordingInterval]) {\n                audioVideoBlobs[recordingInterval] = {};\n            }\n\n            audioVideoBlobs[recordingInterval].video = blob;\n\n            if (audioVideoBlobs[recordingInterval].audio && !audioVideoBlobs[recordingInterval].onDataAvailableEventFired) {\n                audioVideoBlobs[recordingInterval].onDataAvailableEventFired = true;\n                fireOnDataAvailableEvent(audioVideoBlobs[recordingInterval]);\n            }\n        };\n\n        function fireOnDataAvailableEvent(blobs) {\n            recordingInterval++;\n            self.ondataavailable(blobs);\n        }\n\n        videoRecorder.onstop = audioRecorder.onstop = function(error) {\n            self.onstop(error);\n        };\n\n        if (!isMediaRecorder) {\n            // to make sure both audio/video are synced.\n            videoRecorder.onStartedDrawingNonBlankFrames = function() {\n                videoRecorder.clearOldRecordedFrames();\n                audioRecorder.start(timeSlice);\n            };\n            videoRecorder.start(timeSlice);\n        } else {\n            videoRecorder.start(timeSlice);\n        }\n    };\n\n    this.stop = function() {\n        if (audioRecorder) {\n            audioRecorder.stop();\n        }\n        if (videoRecorder) {\n            videoRecorder.stop();\n        }\n    };\n\n    this.ondataavailable = function(blob) {\n        console.log('ondataavailable..', blob);\n    };\n\n    this.onstop = function(error) {\n        console.warn('stopped..', error);\n    };\n\n    this.pause = function() {\n        if (audioRecorder) {\n            audioRecorder.pause();\n        }\n        if (videoRecorder) {\n            videoRecorder.pause();\n        }\n    };\n\n    this.resume = function() {\n        if (audioRecorder) {\n            audioRecorder.resume();\n        }\n        if (videoRecorder) {\n            videoRecorder.resume();\n        }\n    };\n\n    var audioRecorder;\n    var videoRecorder;\n\n    var audioVideoBlobs = {};\n    var recordingInterval = 0;\n}\n\nif (typeof MediaStreamRecorder !== 'undefined') {\n    MediaStreamRecorder.MultiStreamRecorder = MultiStreamRecorder;\n}\n\n// _____________________________\n// Cross-Browser-Declarations.js\n\nvar browserFakeUserAgent = 'Fake/5.0 (FakeOS) AppleWebKit/123 (KHTML, like Gecko) Fake/12.3.4567.89 Fake/123.45';\n\n(function(that) {\n    if (typeof window !== 'undefined') {\n        return;\n    }\n\n    if (typeof window === 'undefined' && typeof global !== 'undefined') {\n        global.navigator = {\n            userAgent: browserFakeUserAgent,\n            getUserMedia: function() {}\n        };\n\n        /*global window:true */\n        that.window = global;\n    } else if (typeof window === 'undefined') {\n        // window = this;\n    }\n\n    if (typeof document === 'undefined') {\n        /*global document:true */\n        that.document = {};\n\n        document.createElement = document.captureStream = document.mozCaptureStream = function() {\n            return {};\n        };\n    }\n\n    if (typeof location === 'undefined') {\n        /*global location:true */\n        that.location = {\n            protocol: 'file:',\n            href: '',\n            hash: ''\n        };\n    }\n\n    if (typeof screen === 'undefined') {\n        /*global screen:true */\n        that.screen = {\n            width: 0,\n            height: 0\n        };\n    }\n})(typeof global !== 'undefined' ? global : window);\n\n// WebAudio API representer\nvar AudioContext = window.AudioContext;\n\nif (typeof AudioContext === 'undefined') {\n    if (typeof webkitAudioContext !== 'undefined') {\n        /*global AudioContext:true */\n        AudioContext = webkitAudioContext;\n    }\n\n    if (typeof mozAudioContext !== 'undefined') {\n        /*global AudioContext:true */\n        AudioContext = mozAudioContext;\n    }\n}\n\nif (typeof window === 'undefined') {\n    /*jshint -W020 */\n    window = {};\n}\n\n// WebAudio API representer\nvar AudioContext = window.AudioContext;\n\nif (typeof AudioContext === 'undefined') {\n    if (typeof webkitAudioContext !== 'undefined') {\n        /*global AudioContext:true */\n        AudioContext = webkitAudioContext;\n    }\n\n    if (typeof mozAudioContext !== 'undefined') {\n        /*global AudioContext:true */\n        AudioContext = mozAudioContext;\n    }\n}\n\n/*jshint -W079 */\nvar URL = window.URL;\n\nif (typeof URL === 'undefined' && typeof webkitURL !== 'undefined') {\n    /*global URL:true */\n    URL = webkitURL;\n}\n\nif (typeof navigator !== 'undefined') {\n    if (typeof navigator.webkitGetUserMedia !== 'undefined') {\n        navigator.getUserMedia = navigator.webkitGetUserMedia;\n    }\n\n    if (typeof navigator.mozGetUserMedia !== 'undefined') {\n        navigator.getUserMedia = navigator.mozGetUserMedia;\n    }\n} else {\n    navigator = {\n        getUserMedia: function() {},\n        userAgent: browserFakeUserAgent\n    };\n}\n\nvar IsEdge = navigator.userAgent.indexOf('Edge') !== -1 && (!!navigator.msSaveBlob || !!navigator.msSaveOrOpenBlob);\n\nvar IsOpera = false;\nif (typeof opera !== 'undefined' && navigator.userAgent && navigator.userAgent.indexOf('OPR/') !== -1) {\n    IsOpera = true;\n}\nvar IsChrome = !IsEdge && !IsEdge && !!navigator.webkitGetUserMedia;\n\nvar MediaStream = window.MediaStream;\n\nif (typeof MediaStream === 'undefined' && typeof webkitMediaStream !== 'undefined') {\n    MediaStream = webkitMediaStream;\n}\n\n/*global MediaStream:true */\nif (typeof MediaStream !== 'undefined') {\n    if (!('getVideoTracks' in MediaStream.prototype)) {\n        MediaStream.prototype.getVideoTracks = function() {\n            if (!this.getTracks) {\n                return [];\n            }\n\n            var tracks = [];\n            this.getTracks.forEach(function(track) {\n                if (track.kind.toString().indexOf('video') !== -1) {\n                    tracks.push(track);\n                }\n            });\n            return tracks;\n        };\n\n        MediaStream.prototype.getAudioTracks = function() {\n            if (!this.getTracks) {\n                return [];\n            }\n\n            var tracks = [];\n            this.getTracks.forEach(function(track) {\n                if (track.kind.toString().indexOf('audio') !== -1) {\n                    tracks.push(track);\n                }\n            });\n            return tracks;\n        };\n    }\n\n    if (!('stop' in MediaStream.prototype)) {\n        MediaStream.prototype.stop = function() {\n            this.getAudioTracks().forEach(function(track) {\n                if (!!track.stop) {\n                    track.stop();\n                }\n            });\n\n            this.getVideoTracks().forEach(function(track) {\n                if (!!track.stop) {\n                    track.stop();\n                }\n            });\n        };\n    }\n}\n\nif (typeof location !== 'undefined') {\n    if (location.href.indexOf('file:') === 0) {\n        console.error('Please load this HTML file on HTTP or HTTPS.');\n    }\n}\n\n// Merge all other data-types except \"function\"\n\nfunction mergeProps(mergein, mergeto) {\n    for (var t in mergeto) {\n        if (typeof mergeto[t] !== 'function') {\n            mergein[t] = mergeto[t];\n        }\n    }\n    return mergein;\n}\n\n// \"dropFirstFrame\" has been added by Graham Roth\n// https://github.com/gsroth\n\nfunction dropFirstFrame(arr) {\n    arr.shift();\n    return arr;\n}\n\n/**\n * @param {Blob} file - File or Blob object. This parameter is required.\n * @param {string} fileName - Optional file name e.g. \"Recorded-Video.webm\"\n * @example\n * invokeSaveAsDialog(blob or file, [optional] fileName);\n * @see {@link https://github.com/muaz-khan/RecordRTC|RecordRTC Source Code}\n */\nfunction invokeSaveAsDialog(file, fileName) {\n    if (!file) {\n        throw 'Blob object is required.';\n    }\n\n    if (!file.type) {\n        try {\n            file.type = 'video/webm';\n        } catch (e) {}\n    }\n\n    var fileExtension = (file.type || 'video/webm').split('/')[1];\n\n    if (fileName && fileName.indexOf('.') !== -1) {\n        var splitted = fileName.split('.');\n        fileName = splitted[0];\n        fileExtension = splitted[1];\n    }\n\n    var fileFullName = (fileName || (Math.round(Math.random() * 9999999999) + 888888888)) + '.' + fileExtension;\n\n    if (typeof navigator.msSaveOrOpenBlob !== 'undefined') {\n        return navigator.msSaveOrOpenBlob(file, fileFullName);\n    } else if (typeof navigator.msSaveBlob !== 'undefined') {\n        return navigator.msSaveBlob(file, fileFullName);\n    }\n\n    var hyperlink = document.createElement('a');\n    hyperlink.href = URL.createObjectURL(file);\n    hyperlink.target = '_blank';\n    hyperlink.download = fileFullName;\n\n    if (!!navigator.mozGetUserMedia) {\n        hyperlink.onclick = function() {\n            (document.body || document.documentElement).removeChild(hyperlink);\n        };\n        (document.body || document.documentElement).appendChild(hyperlink);\n    }\n\n    var evt = new MouseEvent('click', {\n        view: window,\n        bubbles: true,\n        cancelable: true\n    });\n\n    hyperlink.dispatchEvent(evt);\n\n    if (!navigator.mozGetUserMedia) {\n        URL.revokeObjectURL(hyperlink.href);\n    }\n}\n\nfunction bytesToSize(bytes) {\n    var k = 1000;\n    var sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB'];\n    if (bytes === 0) {\n        return '0 Bytes';\n    }\n    var i = parseInt(Math.floor(Math.log(bytes) / Math.log(k)), 10);\n    return (bytes / Math.pow(k, i)).toPrecision(3) + ' ' + sizes[i];\n}\n\n// ______________ (used to handle stuff like http://goo.gl/xmE5eg) issue #129\n// ObjectStore.js\nvar ObjectStore = {\n    AudioContext: AudioContext\n};\n\nfunction isMediaRecorderCompatible() {\n    var isOpera = !!window.opera || navigator.userAgent.indexOf(' OPR/') >= 0;\n    var isChrome = !!window.chrome && !isOpera;\n    var isFirefox = typeof window.InstallTrigger !== 'undefined';\n\n    if (isFirefox) {\n        return true;\n    }\n\n    if (!isChrome) {\n        return false;\n    }\n\n    var nVer = navigator.appVersion;\n    var nAgt = navigator.userAgent;\n    var fullVersion = '' + parseFloat(navigator.appVersion);\n    var majorVersion = parseInt(navigator.appVersion, 10);\n    var nameOffset, verOffset, ix;\n\n    if (isChrome) {\n        verOffset = nAgt.indexOf('Chrome');\n        fullVersion = nAgt.substring(verOffset + 7);\n    }\n\n    // trim the fullVersion string at semicolon/space if present\n    if ((ix = fullVersion.indexOf(';')) !== -1) {\n        fullVersion = fullVersion.substring(0, ix);\n    }\n\n    if ((ix = fullVersion.indexOf(' ')) !== -1) {\n        fullVersion = fullVersion.substring(0, ix);\n    }\n\n    majorVersion = parseInt('' + fullVersion, 10);\n\n    if (isNaN(majorVersion)) {\n        fullVersion = '' + parseFloat(navigator.appVersion);\n        majorVersion = parseInt(navigator.appVersion, 10);\n    }\n\n    return majorVersion >= 49;\n}\n\n// ______________ (used to handle stuff like http://goo.gl/xmE5eg) issue #129\n// ObjectStore.js\nvar ObjectStore = {\n    AudioContext: window.AudioContext || window.webkitAudioContext\n};\n\n// ==================\n// MediaRecorder.js\n\n/**\n * Implementation of https://dvcs.w3.org/hg/dap/raw-file/default/media-stream-capture/MediaRecorder.html\n * The MediaRecorder accepts a mediaStream as input source passed from UA. When recorder starts,\n * a MediaEncoder will be created and accept the mediaStream as input source.\n * Encoder will get the raw data by track data changes, encode it by selected MIME Type, then store the encoded in EncodedBufferCache object.\n * The encoded data will be extracted on every timeslice passed from Start function call or by RequestData function.\n * Thread model:\n * When the recorder starts, it creates a \"Media Encoder\" thread to read data from MediaEncoder object and store buffer in EncodedBufferCache object.\n * Also extract the encoded data and create blobs on every timeslice passed from start function or RequestData function called by UA.\n */\n\nfunction MediaRecorderWrapper(mediaStream) {\n    var self = this;\n\n    /**\n     * This method records MediaStream.\n     * @method\n     * @memberof MediaStreamRecorder\n     * @example\n     * recorder.record();\n     */\n    this.start = function(timeSlice, __disableLogs) {\n        if (!self.mimeType) {\n            self.mimeType = 'video/webm';\n        }\n\n        if (self.mimeType.indexOf('audio') !== -1) {\n            if (mediaStream.getVideoTracks().length && mediaStream.getAudioTracks().length) {\n                var stream;\n                if (!!navigator.mozGetUserMedia) {\n                    stream = new MediaStream();\n                    stream.addTrack(mediaStream.getAudioTracks()[0]);\n                } else {\n                    // webkitMediaStream\n                    stream = new MediaStream(mediaStream.getAudioTracks());\n                }\n                mediaStream = stream;\n            }\n        }\n\n        if (self.mimeType.indexOf('audio') !== -1) {\n            self.mimeType = IsChrome ? 'audio/webm' : 'audio/ogg';\n        }\n\n        self.dontFireOnDataAvailableEvent = false;\n\n        var recorderHints = {\n            mimeType: self.mimeType\n        };\n\n        if (!self.disableLogs && !__disableLogs) {\n            console.log('Passing following params over MediaRecorder API.', recorderHints);\n        }\n\n        if (mediaRecorder) {\n            // mandatory to make sure Firefox doesn't fails to record streams 3-4 times without reloading the page.\n            mediaRecorder = null;\n        }\n\n        if (IsChrome && !isMediaRecorderCompatible()) {\n            // to support video-only recording on stable\n            recorderHints = 'video/vp8';\n        }\n\n        // http://dxr.mozilla.org/mozilla-central/source/content/media/MediaRecorder.cpp\n        // https://wiki.mozilla.org/Gecko:MediaRecorder\n        // https://dvcs.w3.org/hg/dap/raw-file/default/media-stream-capture/MediaRecorder.html\n\n        // starting a recording session; which will initiate \"Reading Thread\"\n        // \"Reading Thread\" are used to prevent main-thread blocking scenarios\n        try {\n            mediaRecorder = new MediaRecorder(mediaStream, recorderHints);\n        } catch (e) {\n            // if someone passed NON_supported mimeType\n            // or if Firefox on Android\n            mediaRecorder = new MediaRecorder(mediaStream);\n        }\n\n        if ('canRecordMimeType' in mediaRecorder && mediaRecorder.canRecordMimeType(self.mimeType) === false) {\n            if (!self.disableLogs) {\n                console.warn('MediaRecorder API seems unable to record mimeType:', self.mimeType);\n            }\n        }\n\n        // i.e. stop recording when <video> is paused by the user; and auto restart recording \n        // when video is resumed. E.g. yourStream.getVideoTracks()[0].muted = true; // it will auto-stop recording.\n        mediaRecorder.ignoreMutedMedia = self.ignoreMutedMedia || false;\n\n        var firedOnDataAvailableOnce = false;\n\n        // Dispatching OnDataAvailable Handler\n        mediaRecorder.ondataavailable = function(e) {\n            if (self.dontFireOnDataAvailableEvent) {\n                return;\n            }\n\n            // how to fix FF-corrupt-webm issues?\n            // should we leave this?          e.data.size < 26800\n            if (!e.data || !e.data.size || e.data.size < 26800 || firedOnDataAvailableOnce) {\n                return;\n            }\n\n            firedOnDataAvailableOnce = true;\n\n            var blob = self.getNativeBlob ? e.data : new Blob([e.data], {\n                type: self.mimeType || 'video/webm'\n            });\n\n            self.ondataavailable(blob);\n\n            self.dontFireOnDataAvailableEvent = true;\n\n            if (!!mediaRecorder) {\n                mediaRecorder.stop();\n                mediaRecorder = null;\n            }\n\n            // record next interval\n            self.start(timeSlice, '__disableLogs');\n        };\n\n        mediaRecorder.onerror = function(error) {\n            if (!self.disableLogs) {\n                if (error.name === 'InvalidState') {\n                    console.error('The MediaRecorder is not in a state in which the proposed operation is allowed to be executed.');\n                } else if (error.name === 'OutOfMemory') {\n                    console.error('The UA has exhaused the available memory. User agents SHOULD provide as much additional information as possible in the message attribute.');\n                } else if (error.name === 'IllegalStreamModification') {\n                    console.error('A modification to the stream has occurred that makes it impossible to continue recording. An example would be the addition of a Track while recording is occurring. User agents SHOULD provide as much additional information as possible in the message attribute.');\n                } else if (error.name === 'OtherRecordingError') {\n                    console.error('Used for an fatal error other than those listed above. User agents SHOULD provide as much additional information as possible in the message attribute.');\n                } else if (error.name === 'GenericError') {\n                    console.error('The UA cannot provide the codec or recording option that has been requested.', error);\n                } else {\n                    console.error('MediaRecorder Error', error);\n                }\n            }\n\n            // When the stream is \"ended\" set recording to 'inactive' \n            // and stop gathering data. Callers should not rely on \n            // exactness of the timeSlice value, especially \n            // if the timeSlice value is small. Callers should \n            // consider timeSlice as a minimum value\n\n            if (!!mediaRecorder && mediaRecorder.state !== 'inactive' && mediaRecorder.state !== 'stopped') {\n                mediaRecorder.stop();\n            }\n        };\n\n        // void start(optional long mTimeSlice)\n        // The interval of passing encoded data from EncodedBufferCache to onDataAvailable\n        // handler. \"mTimeSlice < 0\" means Session object does not push encoded data to\n        // onDataAvailable, instead, it passive wait the client side pull encoded data\n        // by calling requestData API.\n        try {\n            mediaRecorder.start(3.6e+6);\n        } catch (e) {\n            mediaRecorder = null;\n        }\n\n        setTimeout(function() {\n            if (!mediaRecorder) {\n                return;\n            }\n\n            if (mediaRecorder.state === 'recording') {\n                // \"stop\" method auto invokes \"requestData\"!\n                mediaRecorder.requestData();\n                // mediaRecorder.stop();\n            }\n        }, timeSlice);\n\n        // Start recording. If timeSlice has been provided, mediaRecorder will\n        // raise a dataavailable event containing the Blob of collected data on every timeSlice milliseconds.\n        // If timeSlice isn't provided, UA should call the RequestData to obtain the Blob data, also set the mTimeSlice to zero.\n    };\n\n    /**\n     * This method stops recording MediaStream.\n     * @param {function} callback - Callback function, that is used to pass recorded blob back to the callee.\n     * @method\n     * @memberof MediaStreamRecorder\n     * @example\n     * recorder.stop(function(blob) {\n     *     video.src = URL.createObjectURL(blob);\n     * });\n     */\n    this.stop = function(callback) {\n        if (!mediaRecorder) {\n            return;\n        }\n\n        // mediaRecorder.state === 'recording' means that media recorder is associated with \"session\"\n        // mediaRecorder.state === 'stopped' means that media recorder is detached from the \"session\" ... in this case; \"session\" will also be deleted.\n\n        if (mediaRecorder.state === 'recording') {\n            // \"stop\" method auto invokes \"requestData\"!\n            mediaRecorder.requestData();\n\n            setTimeout(function() {\n                self.dontFireOnDataAvailableEvent = true;\n                if (!!mediaRecorder && mediaRecorder.state === 'recording') {\n                    mediaRecorder.stop();\n                }\n                mediaRecorder = null;\n            }, 2000);\n        }\n    };\n\n    /**\n     * This method pauses the recording process.\n     * @method\n     * @memberof MediaStreamRecorder\n     * @example\n     * recorder.pause();\n     */\n    this.pause = function() {\n        if (!mediaRecorder) {\n            return;\n        }\n\n        if (mediaRecorder.state === 'recording') {\n            mediaRecorder.pause();\n        }\n    };\n\n    /**\n     * The recorded blobs are passed over this event.\n     * @event\n     * @memberof MediaStreamRecorder\n     * @example\n     * recorder.ondataavailable = function(data) {};\n     */\n    this.ondataavailable = function(blob) {\n        console.log('recorded-blob', blob);\n    };\n\n    /**\n     * This method resumes the recording process.\n     * @method\n     * @memberof MediaStreamRecorder\n     * @example\n     * recorder.resume();\n     */\n    this.resume = function() {\n        if (this.dontFireOnDataAvailableEvent) {\n            this.dontFireOnDataAvailableEvent = false;\n\n            var disableLogs = self.disableLogs;\n            self.disableLogs = true;\n            this.record();\n            self.disableLogs = disableLogs;\n            return;\n        }\n\n        if (!mediaRecorder) {\n            return;\n        }\n\n        if (mediaRecorder.state === 'paused') {\n            mediaRecorder.resume();\n        }\n    };\n\n    /**\n     * This method resets currently recorded data.\n     * @method\n     * @memberof MediaStreamRecorder\n     * @example\n     * recorder.clearRecordedData();\n     */\n    this.clearRecordedData = function() {\n        if (!mediaRecorder) {\n            return;\n        }\n\n        this.pause();\n\n        this.dontFireOnDataAvailableEvent = true;\n        this.stop();\n    };\n\n    // Reference to \"MediaRecorder\" object\n    var mediaRecorder;\n\n    function isMediaStreamActive() {\n        if ('active' in mediaStream) {\n            if (!mediaStream.active) {\n                return false;\n            }\n        } else if ('ended' in mediaStream) { // old hack\n            if (mediaStream.ended) {\n                return false;\n            }\n        }\n        return true;\n    }\n\n    // this method checks if media stream is stopped\n    // or any track is ended.\n    (function looper() {\n        if (!mediaRecorder) {\n            return;\n        }\n\n        if (isMediaStreamActive() === false) {\n            self.stop();\n            return;\n        }\n\n        setTimeout(looper, 1000); // check every second\n    })();\n}\n\nif (typeof MediaStreamRecorder !== 'undefined') {\n    MediaStreamRecorder.MediaRecorderWrapper = MediaRecorderWrapper;\n}\n\n// ======================\n// StereoAudioRecorder.js\n\nfunction StereoAudioRecorder(mediaStream) {\n    // void start(optional long timeSlice)\n    // timestamp to fire \"ondataavailable\"\n    this.start = function(timeSlice) {\n        timeSlice = timeSlice || 1000;\n\n        mediaRecorder = new StereoAudioRecorderHelper(mediaStream, this);\n\n        mediaRecorder.record();\n\n        timeout = setInterval(function() {\n            mediaRecorder.requestData();\n        }, timeSlice);\n    };\n\n    this.stop = function() {\n        if (mediaRecorder) {\n            mediaRecorder.stop();\n            clearTimeout(timeout);\n        }\n    };\n\n    this.pause = function() {\n        if (!mediaRecorder) {\n            return;\n        }\n\n        mediaRecorder.pause();\n    };\n\n    this.resume = function() {\n        if (!mediaRecorder) {\n            return;\n        }\n\n        mediaRecorder.resume();\n    };\n\n    this.ondataavailable = function() {};\n\n    // Reference to \"StereoAudioRecorder\" object\n    var mediaRecorder;\n    var timeout;\n}\n\nif (typeof MediaStreamRecorder !== 'undefined') {\n    MediaStreamRecorder.StereoAudioRecorder = StereoAudioRecorder;\n}\n\n// ============================\n// StereoAudioRecorderHelper.js\n\n// source code from: http://typedarray.org/wp-content/projects/WebAudioRecorder/script.js\n\nfunction StereoAudioRecorderHelper(mediaStream, root) {\n\n    // variables    \n    var deviceSampleRate = 44100; // range: 22050 to 96000\n\n    if (!ObjectStore.AudioContextConstructor) {\n        ObjectStore.AudioContextConstructor = new ObjectStore.AudioContext();\n    }\n\n    // check device sample rate\n    deviceSampleRate = ObjectStore.AudioContextConstructor.sampleRate;\n\n    var leftchannel = [];\n    var rightchannel = [];\n    var scriptprocessornode;\n    var recording = false;\n    var recordingLength = 0;\n    var volume;\n    var audioInput;\n    var sampleRate = root.sampleRate || deviceSampleRate;\n\n    var mimeType = root.mimeType || 'audio/wav';\n    var isPCM = mimeType.indexOf('audio/pcm') > -1;\n\n    var context;\n\n    var numChannels = root.audioChannels || 2;\n\n    this.record = function() {\n        recording = true;\n        // reset the buffers for the new recording\n        leftchannel.length = rightchannel.length = 0;\n        recordingLength = 0;\n    };\n\n    this.requestData = function() {\n        if (isPaused) {\n            return;\n        }\n\n        if (recordingLength === 0) {\n            requestDataInvoked = false;\n            return;\n        }\n\n        requestDataInvoked = true;\n        // clone stuff\n        var internalLeftChannel = leftchannel.slice(0);\n        var internalRightChannel = rightchannel.slice(0);\n        var internalRecordingLength = recordingLength;\n\n        // reset the buffers for the new recording\n        leftchannel.length = rightchannel.length = [];\n        recordingLength = 0;\n        requestDataInvoked = false;\n\n        // we flat the left and right channels down\n        var leftBuffer = mergeBuffers(internalLeftChannel, internalRecordingLength);\n\n        var interleaved = leftBuffer;\n\n        // we interleave both channels together\n        if (numChannels === 2) {\n            var rightBuffer = mergeBuffers(internalRightChannel, internalRecordingLength); // bug fixed via #70,#71\n            interleaved = interleave(leftBuffer, rightBuffer);\n        }\n\n        if (isPCM) {\n            // our final binary blob\n            var blob = new Blob([convertoFloat32ToInt16(interleaved)], {\n                type: 'audio/pcm'\n            });\n\n            console.debug('audio recorded blob size:', bytesToSize(blob.size));\n            root.ondataavailable(blob);\n            return;\n        }\n\n        // we create our wav file\n        var buffer = new ArrayBuffer(44 + interleaved.length * 2);\n        var view = new DataView(buffer);\n\n        // RIFF chunk descriptor\n        writeUTFBytes(view, 0, 'RIFF');\n\n        // -8 (via #97)\n        view.setUint32(4, 44 + interleaved.length * 2 - 8, true);\n\n        writeUTFBytes(view, 8, 'WAVE');\n        // FMT sub-chunk\n        writeUTFBytes(view, 12, 'fmt ');\n        view.setUint32(16, 16, true);\n        view.setUint16(20, 1, true);\n        // stereo (2 channels)\n        view.setUint16(22, numChannels, true);\n        view.setUint32(24, sampleRate, true);\n        view.setUint32(28, sampleRate * numChannels * 2, true); // numChannels * 2 (via #71)\n        view.setUint16(32, numChannels * 2, true);\n        view.setUint16(34, 16, true);\n        // data sub-chunk\n        writeUTFBytes(view, 36, 'data');\n        view.setUint32(40, interleaved.length * 2, true);\n\n        // write the PCM samples\n        var lng = interleaved.length;\n        var index = 44;\n        var volume = 1;\n        for (var i = 0; i < lng; i++) {\n            view.setInt16(index, interleaved[i] * (0x7FFF * volume), true);\n            index += 2;\n        }\n\n        // our final binary blob\n        var blob = new Blob([view], {\n            type: 'audio/wav'\n        });\n\n        console.debug('audio recorded blob size:', bytesToSize(blob.size));\n\n        root.ondataavailable(blob);\n    };\n\n    this.stop = function() {\n        // we stop recording\n        recording = false;\n        this.requestData();\n\n        audioInput.disconnect();\n    };\n\n    function interleave(leftChannel, rightChannel) {\n        var length = leftChannel.length + rightChannel.length;\n        var result = new Float32Array(length);\n\n        var inputIndex = 0;\n\n        for (var index = 0; index < length;) {\n            result[index++] = leftChannel[inputIndex];\n            result[index++] = rightChannel[inputIndex];\n            inputIndex++;\n        }\n        return result;\n    }\n\n    function mergeBuffers(channelBuffer, recordingLength) {\n        var result = new Float32Array(recordingLength);\n        var offset = 0;\n        var lng = channelBuffer.length;\n        for (var i = 0; i < lng; i++) {\n            var buffer = channelBuffer[i];\n            result.set(buffer, offset);\n            offset += buffer.length;\n        }\n        return result;\n    }\n\n    function writeUTFBytes(view, offset, string) {\n        var lng = string.length;\n        for (var i = 0; i < lng; i++) {\n            view.setUint8(offset + i, string.charCodeAt(i));\n        }\n    }\n\n    function convertoFloat32ToInt16(buffer) {\n        var l = buffer.length;\n        var buf = new Int16Array(l)\n\n        while (l--) {\n            buf[l] = buffer[l] * 0xFFFF; //convert to 16 bit\n        }\n        return buf.buffer\n    }\n\n    // creates the audio context\n    var context = ObjectStore.AudioContextConstructor;\n\n    // creates a gain node\n    ObjectStore.VolumeGainNode = context.createGain();\n\n    var volume = ObjectStore.VolumeGainNode;\n\n    // creates an audio node from the microphone incoming stream\n    ObjectStore.AudioInput = context.createMediaStreamSource(mediaStream);\n\n    // creates an audio node from the microphone incoming stream\n    var audioInput = ObjectStore.AudioInput;\n\n    // connect the stream to the gain node\n    audioInput.connect(volume);\n\n    /* From the spec: This value controls how frequently the audioprocess event is\n    dispatched and how many sample-frames need to be processed each call.\n    Lower values for buffer size will result in a lower (better) latency.\n    Higher values will be necessary to avoid audio breakup and glitches \n    Legal values are 256, 512, 1024, 2048, 4096, 8192, and 16384.*/\n    var bufferSize = root.bufferSize || 2048;\n    if (root.bufferSize === 0) {\n        bufferSize = 0;\n    }\n\n    if (context.createJavaScriptNode) {\n        scriptprocessornode = context.createJavaScriptNode(bufferSize, numChannels, numChannels);\n    } else if (context.createScriptProcessor) {\n        scriptprocessornode = context.createScriptProcessor(bufferSize, numChannels, numChannels);\n    } else {\n        throw 'WebAudio API has no support on this browser.';\n    }\n\n    bufferSize = scriptprocessornode.bufferSize;\n\n    console.debug('using audio buffer-size:', bufferSize);\n\n    var requestDataInvoked = false;\n\n    // sometimes \"scriptprocessornode\" disconnects from he destination-node\n    // and there is no exception thrown in this case.\n    // and obviously no further \"ondataavailable\" events will be emitted.\n    // below global-scope variable is added to debug such unexpected but \"rare\" cases.\n    window.scriptprocessornode = scriptprocessornode;\n\n    if (numChannels === 1) {\n        console.debug('All right-channels are skipped.');\n    }\n\n    var isPaused = false;\n\n    this.pause = function() {\n        isPaused = true;\n    };\n\n    this.resume = function() {\n        isPaused = false;\n    };\n\n    // http://webaudio.github.io/web-audio-api/#the-scriptprocessornode-interface\n    scriptprocessornode.onaudioprocess = function(e) {\n        if (!recording || requestDataInvoked || isPaused) {\n            return;\n        }\n\n        var left = e.inputBuffer.getChannelData(0);\n        leftchannel.push(new Float32Array(left));\n\n        if (numChannels === 2) {\n            var right = e.inputBuffer.getChannelData(1);\n            rightchannel.push(new Float32Array(right));\n        }\n        recordingLength += bufferSize;\n    };\n\n    volume.connect(scriptprocessornode);\n    scriptprocessornode.connect(context.destination);\n}\n\nif (typeof MediaStreamRecorder !== 'undefined') {\n    MediaStreamRecorder.StereoAudioRecorderHelper = StereoAudioRecorderHelper;\n}\n\n// ===================\n// WhammyRecorder.js\n\nfunction WhammyRecorder(mediaStream) {\n    // void start(optional long timeSlice)\n    // timestamp to fire \"ondataavailable\"\n    this.start = function(timeSlice) {\n        timeSlice = timeSlice || 1000;\n\n        mediaRecorder = new WhammyRecorderHelper(mediaStream, this);\n\n        for (var prop in this) {\n            if (typeof this[prop] !== 'function') {\n                mediaRecorder[prop] = this[prop];\n            }\n        }\n\n        mediaRecorder.record();\n\n        timeout = setInterval(function() {\n            mediaRecorder.requestData();\n        }, timeSlice);\n    };\n\n    this.stop = function() {\n        if (mediaRecorder) {\n            mediaRecorder.stop();\n            clearTimeout(timeout);\n        }\n    };\n\n    this.clearOldRecordedFrames = function() {\n        if (mediaRecorder) {\n            mediaRecorder.clearOldRecordedFrames();\n        }\n    };\n\n    this.pause = function() {\n        if (!mediaRecorder) {\n            return;\n        }\n\n        mediaRecorder.pause();\n    };\n\n    this.resume = function() {\n        if (!mediaRecorder) {\n            return;\n        }\n\n        mediaRecorder.resume();\n    };\n\n    this.ondataavailable = function() {};\n\n    // Reference to \"WhammyRecorder\" object\n    var mediaRecorder;\n    var timeout;\n}\n\nif (typeof MediaStreamRecorder !== 'undefined') {\n    MediaStreamRecorder.WhammyRecorder = WhammyRecorder;\n}\n\n// ==========================\n// WhammyRecorderHelper.js\n\nfunction WhammyRecorderHelper(mediaStream, root) {\n    this.record = function(timeSlice) {\n        if (!this.width) {\n            this.width = 320;\n        }\n        if (!this.height) {\n            this.height = 240;\n        }\n\n        if (this.video && this.video instanceof HTMLVideoElement) {\n            if (!this.width) {\n                this.width = video.videoWidth || video.clientWidth || 320;\n            }\n            if (!this.height) {\n                this.height = video.videoHeight || video.clientHeight || 240;\n            }\n        }\n\n        if (!this.video) {\n            this.video = {\n                width: this.width,\n                height: this.height\n            };\n        }\n\n        if (!this.canvas || !this.canvas.width || !this.canvas.height) {\n            this.canvas = {\n                width: this.width,\n                height: this.height\n            };\n        }\n\n        canvas.width = this.canvas.width;\n        canvas.height = this.canvas.height;\n\n        // setting defaults\n        if (this.video && this.video instanceof HTMLVideoElement) {\n            this.isHTMLObject = true;\n            video = this.video.cloneNode();\n        } else {\n            video = document.createElement('video');\n            video.src = URL.createObjectURL(mediaStream);\n\n            video.width = this.video.width;\n            video.height = this.video.height;\n        }\n\n        video.muted = true;\n        video.play();\n\n        lastTime = new Date().getTime();\n        whammy = new Whammy.Video(root.speed, root.quality);\n\n        console.log('canvas resolutions', canvas.width, '*', canvas.height);\n        console.log('video width/height', video.width || canvas.width, '*', video.height || canvas.height);\n\n        drawFrames();\n    };\n\n    this.clearOldRecordedFrames = function() {\n        whammy.frames = [];\n    };\n\n    var requestDataInvoked = false;\n    this.requestData = function() {\n        if (isPaused) {\n            return;\n        }\n\n        if (!whammy.frames.length) {\n            requestDataInvoked = false;\n            return;\n        }\n\n        requestDataInvoked = true;\n        // clone stuff\n        var internalFrames = whammy.frames.slice(0);\n\n        // reset the frames for the new recording\n\n        whammy.frames = dropBlackFrames(internalFrames, -1);\n\n        whammy.compile(function(whammyBlob) {\n            root.ondataavailable(whammyBlob);\n            console.debug('video recorded blob size:', bytesToSize(whammyBlob.size));\n        });\n\n        whammy.frames = [];\n\n        requestDataInvoked = false;\n    };\n\n    var isOnStartedDrawingNonBlankFramesInvoked = false;\n\n    function drawFrames() {\n        if (isPaused) {\n            lastTime = new Date().getTime();\n            setTimeout(drawFrames, 500);\n            return;\n        }\n\n        if (isStopDrawing) {\n            return;\n        }\n\n        if (requestDataInvoked) {\n            return setTimeout(drawFrames, 100);\n        }\n\n        var duration = new Date().getTime() - lastTime;\n        if (!duration) {\n            return drawFrames();\n        }\n\n        // via webrtc-experiment#206, by Jack i.e. @Seymourr\n        lastTime = new Date().getTime();\n\n        if (!self.isHTMLObject && video.paused) {\n            video.play(); // Android\n        }\n\n        context.drawImage(video, 0, 0, canvas.width, canvas.height);\n\n        if (!isStopDrawing) {\n            whammy.frames.push({\n                duration: duration,\n                image: canvas.toDataURL('image/webp')\n            });\n        }\n\n        if (!isOnStartedDrawingNonBlankFramesInvoked && !isBlankFrame(whammy.frames[whammy.frames.length - 1])) {\n            isOnStartedDrawingNonBlankFramesInvoked = true;\n            root.onStartedDrawingNonBlankFrames();\n        }\n\n        setTimeout(drawFrames, 10);\n    }\n\n    var isStopDrawing = false;\n\n    this.stop = function() {\n        isStopDrawing = true;\n        this.requestData();\n    };\n\n    var canvas = document.createElement('canvas');\n    var context = canvas.getContext('2d');\n\n    var video;\n    var lastTime;\n    var whammy;\n\n    var self = this;\n\n    function isBlankFrame(frame, _pixTolerance, _frameTolerance) {\n        var localCanvas = document.createElement('canvas');\n        localCanvas.width = canvas.width;\n        localCanvas.height = canvas.height;\n        var context2d = localCanvas.getContext('2d');\n\n        var sampleColor = {\n            r: 0,\n            g: 0,\n            b: 0\n        };\n        var maxColorDifference = Math.sqrt(\n            Math.pow(255, 2) +\n            Math.pow(255, 2) +\n            Math.pow(255, 2)\n        );\n        var pixTolerance = _pixTolerance && _pixTolerance >= 0 && _pixTolerance <= 1 ? _pixTolerance : 0;\n        var frameTolerance = _frameTolerance && _frameTolerance >= 0 && _frameTolerance <= 1 ? _frameTolerance : 0;\n\n        var matchPixCount, endPixCheck, maxPixCount;\n\n        var image = new Image();\n        image.src = frame.image;\n        context2d.drawImage(image, 0, 0, canvas.width, canvas.height);\n        var imageData = context2d.getImageData(0, 0, canvas.width, canvas.height);\n        matchPixCount = 0;\n        endPixCheck = imageData.data.length;\n        maxPixCount = imageData.data.length / 4;\n\n        for (var pix = 0; pix < endPixCheck; pix += 4) {\n            var currentColor = {\n                r: imageData.data[pix],\n                g: imageData.data[pix + 1],\n                b: imageData.data[pix + 2]\n            };\n            var colorDifference = Math.sqrt(\n                Math.pow(currentColor.r - sampleColor.r, 2) +\n                Math.pow(currentColor.g - sampleColor.g, 2) +\n                Math.pow(currentColor.b - sampleColor.b, 2)\n            );\n            // difference in color it is difference in color vectors (r1,g1,b1) <=> (r2,g2,b2)\n            if (colorDifference <= maxColorDifference * pixTolerance) {\n                matchPixCount++;\n            }\n        }\n\n        if (maxPixCount - matchPixCount <= maxPixCount * frameTolerance) {\n            return false;\n        } else {\n            return true;\n        }\n    }\n\n    function dropBlackFrames(_frames, _framesToCheck, _pixTolerance, _frameTolerance) {\n        var localCanvas = document.createElement('canvas');\n        localCanvas.width = canvas.width;\n        localCanvas.height = canvas.height;\n        var context2d = localCanvas.getContext('2d');\n        var resultFrames = [];\n\n        var checkUntilNotBlack = _framesToCheck === -1;\n        var endCheckFrame = (_framesToCheck && _framesToCheck > 0 && _framesToCheck <= _frames.length) ?\n            _framesToCheck : _frames.length;\n        var sampleColor = {\n            r: 0,\n            g: 0,\n            b: 0\n        };\n        var maxColorDifference = Math.sqrt(\n            Math.pow(255, 2) +\n            Math.pow(255, 2) +\n            Math.pow(255, 2)\n        );\n        var pixTolerance = _pixTolerance && _pixTolerance >= 0 && _pixTolerance <= 1 ? _pixTolerance : 0;\n        var frameTolerance = _frameTolerance && _frameTolerance >= 0 && _frameTolerance <= 1 ? _frameTolerance : 0;\n        var doNotCheckNext = false;\n\n        for (var f = 0; f < endCheckFrame; f++) {\n            var matchPixCount, endPixCheck, maxPixCount;\n\n            if (!doNotCheckNext) {\n                var image = new Image();\n                image.src = _frames[f].image;\n                context2d.drawImage(image, 0, 0, canvas.width, canvas.height);\n                var imageData = context2d.getImageData(0, 0, canvas.width, canvas.height);\n                matchPixCount = 0;\n                endPixCheck = imageData.data.length;\n                maxPixCount = imageData.data.length / 4;\n\n                for (var pix = 0; pix < endPixCheck; pix += 4) {\n                    var currentColor = {\n                        r: imageData.data[pix],\n                        g: imageData.data[pix + 1],\n                        b: imageData.data[pix + 2]\n                    };\n                    var colorDifference = Math.sqrt(\n                        Math.pow(currentColor.r - sampleColor.r, 2) +\n                        Math.pow(currentColor.g - sampleColor.g, 2) +\n                        Math.pow(currentColor.b - sampleColor.b, 2)\n                    );\n                    // difference in color it is difference in color vectors (r1,g1,b1) <=> (r2,g2,b2)\n                    if (colorDifference <= maxColorDifference * pixTolerance) {\n                        matchPixCount++;\n                    }\n                }\n            }\n\n            if (!doNotCheckNext && maxPixCount - matchPixCount <= maxPixCount * frameTolerance) {\n                // console.log('removed black frame : ' + f + ' ; frame duration ' + _frames[f].duration);\n            } else {\n                // console.log('frame is passed : ' + f);\n                if (checkUntilNotBlack) {\n                    doNotCheckNext = true;\n                }\n                resultFrames.push(_frames[f]);\n            }\n        }\n\n        resultFrames = resultFrames.concat(_frames.slice(endCheckFrame));\n\n        if (resultFrames.length <= 0) {\n            // at least one last frame should be available for next manipulation\n            // if total duration of all frames will be < 1000 than ffmpeg doesn't work well...\n            resultFrames.push(_frames[_frames.length - 1]);\n        }\n\n        return resultFrames;\n    }\n\n    var isPaused = false;\n\n    this.pause = function() {\n        isPaused = true;\n    };\n\n    this.resume = function() {\n        isPaused = false;\n    };\n}\n\nif (typeof MediaStreamRecorder !== 'undefined') {\n    MediaStreamRecorder.WhammyRecorderHelper = WhammyRecorderHelper;\n}\n\n// --------------\n// GifRecorder.js\n\nfunction GifRecorder(mediaStream) {\n    if (typeof GIFEncoder === 'undefined') {\n        throw 'Please link: https://cdn.webrtc-experiment.com/gif-recorder.js';\n    }\n\n    // void start(optional long timeSlice)\n    // timestamp to fire \"ondataavailable\"\n    this.start = function(timeSlice) {\n        timeSlice = timeSlice || 1000;\n\n        var imageWidth = this.videoWidth || 320;\n        var imageHeight = this.videoHeight || 240;\n\n        canvas.width = video.width = imageWidth;\n        canvas.height = video.height = imageHeight;\n\n        // external library to record as GIF images\n        gifEncoder = new GIFEncoder();\n\n        // void setRepeat(int iter)\n        // Sets the number of times the set of GIF frames should be played.\n        // Default is 1; 0 means play indefinitely.\n        gifEncoder.setRepeat(0);\n\n        // void setFrameRate(Number fps)\n        // Sets frame rate in frames per second.\n        // Equivalent to setDelay(1000/fps).\n        // Using \"setDelay\" instead of \"setFrameRate\"\n        gifEncoder.setDelay(this.frameRate || this.speed || 200);\n\n        // void setQuality(int quality)\n        // Sets quality of color quantization (conversion of images to the\n        // maximum 256 colors allowed by the GIF specification).\n        // Lower values (minimum = 1) produce better colors,\n        // but slow processing significantly. 10 is the default,\n        // and produces good color mapping at reasonable speeds.\n        // Values greater than 20 do not yield significant improvements in speed.\n        gifEncoder.setQuality(this.quality || 1);\n\n        // Boolean start()\n        // This writes the GIF Header and returns false if it fails.\n        gifEncoder.start();\n\n        startTime = Date.now();\n\n        function drawVideoFrame(time) {\n            if (isPaused) {\n                setTimeout(drawVideoFrame, 500, time);\n                return;\n            }\n\n            lastAnimationFrame = requestAnimationFrame(drawVideoFrame);\n\n            if (typeof lastFrameTime === undefined) {\n                lastFrameTime = time;\n            }\n\n            // ~10 fps\n            if (time - lastFrameTime < 90) {\n                return;\n            }\n\n            if (video.paused) {\n                video.play(); // Android\n            }\n\n            context.drawImage(video, 0, 0, imageWidth, imageHeight);\n\n            gifEncoder.addFrame(context);\n\n            // console.log('Recording...' + Math.round((Date.now() - startTime) / 1000) + 's');\n            // console.log(\"fps: \", 1000 / (time - lastFrameTime));\n\n            lastFrameTime = time;\n        }\n\n        lastAnimationFrame = requestAnimationFrame(drawVideoFrame);\n\n        timeout = setTimeout(doneRecording, timeSlice);\n    };\n\n    function doneRecording() {\n        endTime = Date.now();\n\n        var gifBlob = new Blob([new Uint8Array(gifEncoder.stream().bin)], {\n            type: 'image/gif'\n        });\n        self.ondataavailable(gifBlob);\n\n        // todo: find a way to clear old recorded blobs\n        gifEncoder.stream().bin = [];\n    }\n\n    this.stop = function() {\n        if (lastAnimationFrame) {\n            cancelAnimationFrame(lastAnimationFrame);\n            clearTimeout(timeout);\n            doneRecording();\n        }\n    };\n\n    var isPaused = false;\n\n    this.pause = function() {\n        isPaused = true;\n    };\n\n    this.resume = function() {\n        isPaused = false;\n    };\n\n    this.ondataavailable = function() {};\n    this.onstop = function() {};\n\n    // Reference to itself\n    var self = this;\n\n    var canvas = document.createElement('canvas');\n    var context = canvas.getContext('2d');\n\n    var video = document.createElement('video');\n    video.muted = true;\n    video.autoplay = true;\n    video.src = URL.createObjectURL(mediaStream);\n    video.play();\n\n    var lastAnimationFrame = null;\n    var startTime, endTime, lastFrameTime;\n\n    var gifEncoder;\n    var timeout;\n}\n\nif (typeof MediaStreamRecorder !== 'undefined') {\n    MediaStreamRecorder.GifRecorder = GifRecorder;\n}\n\n// https://github.com/antimatter15/whammy/blob/master/LICENSE\n// _________\n// Whammy.js\n\n// todo: Firefox now supports webp for webm containers!\n// their MediaRecorder implementation works well!\n// should we provide an option to record via Whammy.js or MediaRecorder API is a better solution?\n\n/**\n * Whammy is a standalone class used by {@link RecordRTC} to bring video recording in Chrome. It is written by {@link https://github.com/antimatter15|antimatter15}\n * @summary A real time javascript webm encoder based on a canvas hack.\n * @typedef Whammy\n * @class\n * @example\n * var recorder = new Whammy().Video(15);\n * recorder.add(context || canvas || dataURL);\n * var output = recorder.compile();\n */\n\nvar Whammy = (function() {\n    // a more abstract-ish API\n\n    function WhammyVideo(duration, quality) {\n        this.frames = [];\n        if (!duration) {\n            duration = 1;\n        }\n        this.duration = 1000 / duration;\n        this.quality = quality || 0.8;\n    }\n\n    /**\n     * Pass Canvas or Context or image/webp(string) to {@link Whammy} encoder.\n     * @method\n     * @memberof Whammy\n     * @example\n     * recorder = new Whammy().Video(0.8, 100);\n     * recorder.add(canvas || context || 'image/webp');\n     * @param {string} frame - Canvas || Context || image/webp\n     * @param {number} duration - Stick a duration (in milliseconds)\n     */\n    WhammyVideo.prototype.add = function(frame, duration) {\n        if ('canvas' in frame) { //CanvasRenderingContext2D\n            frame = frame.canvas;\n        }\n\n        if ('toDataURL' in frame) {\n            frame = frame.toDataURL('image/webp', this.quality);\n        }\n\n        if (!(/^data:image\\/webp;base64,/ig).test(frame)) {\n            throw 'Input must be formatted properly as a base64 encoded DataURI of type image/webp';\n        }\n        this.frames.push({\n            image: frame,\n            duration: duration || this.duration\n        });\n    };\n\n    function processInWebWorker(_function) {\n        var blob = URL.createObjectURL(new Blob([_function.toString(),\n            'this.onmessage =  function (e) {' + _function.name + '(e.data);}'\n        ], {\n            type: 'application/javascript'\n        }));\n\n        var worker = new Worker(blob);\n        URL.revokeObjectURL(blob);\n        return worker;\n    }\n\n    function whammyInWebWorker(frames) {\n        function ArrayToWebM(frames) {\n            var info = checkFrames(frames);\n            if (!info) {\n                return [];\n            }\n\n            var clusterMaxDuration = 30000;\n\n            var EBML = [{\n                'id': 0x1a45dfa3, // EBML\n                'data': [{\n                    'data': 1,\n                    'id': 0x4286 // EBMLVersion\n                }, {\n                    'data': 1,\n                    'id': 0x42f7 // EBMLReadVersion\n                }, {\n                    'data': 4,\n                    'id': 0x42f2 // EBMLMaxIDLength\n                }, {\n                    'data': 8,\n                    'id': 0x42f3 // EBMLMaxSizeLength\n                }, {\n                    'data': 'webm',\n                    'id': 0x4282 // DocType\n                }, {\n                    'data': 2,\n                    'id': 0x4287 // DocTypeVersion\n                }, {\n                    'data': 2,\n                    'id': 0x4285 // DocTypeReadVersion\n                }]\n            }, {\n                'id': 0x18538067, // Segment\n                'data': [{\n                    'id': 0x1549a966, // Info\n                    'data': [{\n                        'data': 1e6, //do things in millisecs (num of nanosecs for duration scale)\n                        'id': 0x2ad7b1 // TimecodeScale\n                    }, {\n                        'data': 'whammy',\n                        'id': 0x4d80 // MuxingApp\n                    }, {\n                        'data': 'whammy',\n                        'id': 0x5741 // WritingApp\n                    }, {\n                        'data': doubleToString(info.duration),\n                        'id': 0x4489 // Duration\n                    }]\n                }, {\n                    'id': 0x1654ae6b, // Tracks\n                    'data': [{\n                        'id': 0xae, // TrackEntry\n                        'data': [{\n                            'data': 1,\n                            'id': 0xd7 // TrackNumber\n                        }, {\n                            'data': 1,\n                            'id': 0x73c5 // TrackUID\n                        }, {\n                            'data': 0,\n                            'id': 0x9c // FlagLacing\n                        }, {\n                            'data': 'und',\n                            'id': 0x22b59c // Language\n                        }, {\n                            'data': 'V_VP8',\n                            'id': 0x86 // CodecID\n                        }, {\n                            'data': 'VP8',\n                            'id': 0x258688 // CodecName\n                        }, {\n                            'data': 1,\n                            'id': 0x83 // TrackType\n                        }, {\n                            'id': 0xe0, // Video\n                            'data': [{\n                                'data': info.width,\n                                'id': 0xb0 // PixelWidth\n                            }, {\n                                'data': info.height,\n                                'id': 0xba // PixelHeight\n                            }]\n                        }]\n                    }]\n                }]\n            }];\n\n            //Generate clusters (max duration)\n            var frameNumber = 0;\n            var clusterTimecode = 0;\n            while (frameNumber < frames.length) {\n\n                var clusterFrames = [];\n                var clusterDuration = 0;\n                do {\n                    clusterFrames.push(frames[frameNumber]);\n                    clusterDuration += frames[frameNumber].duration;\n                    frameNumber++;\n                } while (frameNumber < frames.length && clusterDuration < clusterMaxDuration);\n\n                var clusterCounter = 0;\n                var cluster = {\n                    'id': 0x1f43b675, // Cluster\n                    'data': getClusterData(clusterTimecode, clusterCounter, clusterFrames)\n                }; //Add cluster to segment\n                EBML[1].data.push(cluster);\n                clusterTimecode += clusterDuration;\n            }\n\n            return generateEBML(EBML);\n        }\n\n        function getClusterData(clusterTimecode, clusterCounter, clusterFrames) {\n            return [{\n                'data': clusterTimecode,\n                'id': 0xe7 // Timecode\n            }].concat(clusterFrames.map(function(webp) {\n                var block = makeSimpleBlock({\n                    discardable: 0,\n                    frame: webp.data.slice(4),\n                    invisible: 0,\n                    keyframe: 1,\n                    lacing: 0,\n                    trackNum: 1,\n                    timecode: Math.round(clusterCounter)\n                });\n                clusterCounter += webp.duration;\n                return {\n                    data: block,\n                    id: 0xa3\n                };\n            }));\n        }\n\n        // sums the lengths of all the frames and gets the duration\n\n        function checkFrames(frames) {\n            if (!frames[0]) {\n                postMessage({\n                    error: 'Something went wrong. Maybe WebP format is not supported in the current browser.'\n                });\n                return;\n            }\n\n            var width = frames[0].width,\n                height = frames[0].height,\n                duration = frames[0].duration;\n\n            for (var i = 1; i < frames.length; i++) {\n                duration += frames[i].duration;\n            }\n            return {\n                duration: duration,\n                width: width,\n                height: height\n            };\n        }\n\n        function numToBuffer(num) {\n            var parts = [];\n            while (num > 0) {\n                parts.push(num & 0xff);\n                num = num >> 8;\n            }\n            return new Uint8Array(parts.reverse());\n        }\n\n        function strToBuffer(str) {\n            return new Uint8Array(str.split('').map(function(e) {\n                return e.charCodeAt(0);\n            }));\n        }\n\n        function bitsToBuffer(bits) {\n            var data = [];\n            var pad = (bits.length % 8) ? (new Array(1 + 8 - (bits.length % 8))).join('0') : '';\n            bits = pad + bits;\n            for (var i = 0; i < bits.length; i += 8) {\n                data.push(parseInt(bits.substr(i, 8), 2));\n            }\n            return new Uint8Array(data);\n        }\n\n        function generateEBML(json) {\n            var ebml = [];\n            for (var i = 0; i < json.length; i++) {\n                var data = json[i].data;\n\n                if (typeof data === 'object') {\n                    data = generateEBML(data);\n                }\n\n                if (typeof data === 'number') {\n                    data = bitsToBuffer(data.toString(2));\n                }\n\n                if (typeof data === 'string') {\n                    data = strToBuffer(data);\n                }\n\n                var len = data.size || data.byteLength || data.length;\n                var zeroes = Math.ceil(Math.ceil(Math.log(len) / Math.log(2)) / 8);\n                var sizeToString = len.toString(2);\n                var padded = (new Array((zeroes * 7 + 7 + 1) - sizeToString.length)).join('0') + sizeToString;\n                var size = (new Array(zeroes)).join('0') + '1' + padded;\n\n                ebml.push(numToBuffer(json[i].id));\n                ebml.push(bitsToBuffer(size));\n                ebml.push(data);\n            }\n\n            return new Blob(ebml, {\n                type: 'video/webm'\n            });\n        }\n\n        function toBinStrOld(bits) {\n            var data = '';\n            var pad = (bits.length % 8) ? (new Array(1 + 8 - (bits.length % 8))).join('0') : '';\n            bits = pad + bits;\n            for (var i = 0; i < bits.length; i += 8) {\n                data += String.fromCharCode(parseInt(bits.substr(i, 8), 2));\n            }\n            return data;\n        }\n\n        function makeSimpleBlock(data) {\n            var flags = 0;\n\n            if (data.keyframe) {\n                flags |= 128;\n            }\n\n            if (data.invisible) {\n                flags |= 8;\n            }\n\n            if (data.lacing) {\n                flags |= (data.lacing << 1);\n            }\n\n            if (data.discardable) {\n                flags |= 1;\n            }\n\n            if (data.trackNum > 127) {\n                throw 'TrackNumber > 127 not supported';\n            }\n\n            var out = [data.trackNum | 0x80, data.timecode >> 8, data.timecode & 0xff, flags].map(function(e) {\n                return String.fromCharCode(e);\n            }).join('') + data.frame;\n\n            return out;\n        }\n\n        function parseWebP(riff) {\n            var VP8 = riff.RIFF[0].WEBP[0];\n\n            var frameStart = VP8.indexOf('\\x9d\\x01\\x2a'); // A VP8 keyframe starts with the 0x9d012a header\n            for (var i = 0, c = []; i < 4; i++) {\n                c[i] = VP8.charCodeAt(frameStart + 3 + i);\n            }\n\n            var width, height, tmp;\n\n            //the code below is literally copied verbatim from the bitstream spec\n            tmp = (c[1] << 8) | c[0];\n            width = tmp & 0x3FFF;\n            tmp = (c[3] << 8) | c[2];\n            height = tmp & 0x3FFF;\n            return {\n                width: width,\n                height: height,\n                data: VP8,\n                riff: riff\n            };\n        }\n\n        function getStrLength(string, offset) {\n            return parseInt(string.substr(offset + 4, 4).split('').map(function(i) {\n                var unpadded = i.charCodeAt(0).toString(2);\n                return (new Array(8 - unpadded.length + 1)).join('0') + unpadded;\n            }).join(''), 2);\n        }\n\n        function parseRIFF(string) {\n            var offset = 0;\n            var chunks = {};\n\n            while (offset < string.length) {\n                var id = string.substr(offset, 4);\n                var len = getStrLength(string, offset);\n                var data = string.substr(offset + 4 + 4, len);\n                offset += 4 + 4 + len;\n                chunks[id] = chunks[id] || [];\n\n                if (id === 'RIFF' || id === 'LIST') {\n                    chunks[id].push(parseRIFF(data));\n                } else {\n                    chunks[id].push(data);\n                }\n            }\n            return chunks;\n        }\n\n        function doubleToString(num) {\n            return [].slice.call(\n                new Uint8Array((new Float64Array([num])).buffer), 0).map(function(e) {\n                return String.fromCharCode(e);\n            }).reverse().join('');\n        }\n\n        var webm = new ArrayToWebM(frames.map(function(frame) {\n            var webp = parseWebP(parseRIFF(atob(frame.image.slice(23))));\n            webp.duration = frame.duration;\n            return webp;\n        }));\n\n        postMessage(webm);\n    }\n\n    /**\n     * Encodes frames in WebM container. It uses WebWorkinvoke to invoke 'ArrayToWebM' method.\n     * @param {function} callback - Callback function, that is used to pass recorded blob back to the callee.\n     * @method\n     * @memberof Whammy\n     * @example\n     * recorder = new Whammy().Video(0.8, 100);\n     * recorder.compile(function(blob) {\n     *    // blob.size - blob.type\n     * });\n     */\n    WhammyVideo.prototype.compile = function(callback) {\n        var webWorker = processInWebWorker(whammyInWebWorker);\n\n        webWorker.onmessage = function(event) {\n            if (event.data.error) {\n                console.error(event.data.error);\n                return;\n            }\n            callback(event.data);\n        };\n\n        webWorker.postMessage(this.frames);\n    };\n\n    return {\n        /**\n         * A more abstract-ish API.\n         * @method\n         * @memberof Whammy\n         * @example\n         * recorder = new Whammy().Video(0.8, 100);\n         * @param {?number} speed - 0.8\n         * @param {?number} quality - 100\n         */\n        Video: WhammyVideo\n    };\n})();\n\nif (typeof MediaStreamRecorder !== 'undefined') {\n    MediaStreamRecorder.Whammy = Whammy;\n}\n\n// Last time updated at Nov 18, 2014, 08:32:23\n\n// Latest file can be found here: https://cdn.webrtc-experiment.com/ConcatenateBlobs.js\n\n// Muaz Khan    - www.MuazKhan.com\n// MIT License  - www.WebRTC-Experiment.com/licence\n// Source Code  - https://github.com/muaz-khan/ConcatenateBlobs\n// Demo         - https://www.WebRTC-Experiment.com/ConcatenateBlobs/\n\n// ___________________\n// ConcatenateBlobs.js\n\n// Simply pass array of blobs.\n// This javascript library will concatenate all blobs in single \"Blob\" object.\n\n(function() {\n    window.ConcatenateBlobs = function(blobs, type, callback) {\n        var buffers = [];\n\n        var index = 0;\n\n        function readAsArrayBuffer() {\n            if (!blobs[index]) {\n                return concatenateBuffers();\n            }\n            var reader = new FileReader();\n            reader.onload = function(event) {\n                buffers.push(event.target.result);\n                index++;\n                readAsArrayBuffer();\n            };\n            reader.readAsArrayBuffer(blobs[index]);\n        }\n\n        readAsArrayBuffer();\n\n        function concatenateBuffers() {\n            var byteLength = 0;\n            buffers.forEach(function(buffer) {\n                byteLength += buffer.byteLength;\n            });\n\n            var tmp = new Uint16Array(byteLength);\n            var lastOffset = 0;\n            buffers.forEach(function(buffer) {\n                // BYTES_PER_ELEMENT == 2 for Uint16Array\n                var reusableByteLength = buffer.byteLength;\n                if (reusableByteLength % 2 != 0) {\n                    buffer = buffer.slice(0, reusableByteLength - 1)\n                }\n                tmp.set(new Uint16Array(buffer), lastOffset);\n                lastOffset += reusableByteLength;\n            });\n\n            var blob = new Blob([tmp.buffer], {\n                type: type\n            });\n\n            callback(blob);\n        }\n    };\n})();\n\n// https://github.com/streamproc/MediaStreamRecorder/issues/42\nif (true /* && !!module.exports*/ ) {\n    module.exports = MediaStreamRecorder;\n}\n\nif (true) {\n    !(__WEBPACK_AMD_DEFINE_ARRAY__ = [], __WEBPACK_AMD_DEFINE_RESULT__ = (function() {\n        return MediaStreamRecorder;\n    }).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n}\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\")))\n\n//# sourceURL=webpack:///./node_modules/msr/MediaStreamRecorder.js?");

/***/ }),

/***/ "./node_modules/multistreamsmixer/MultiStreamsMixer.js":
/*!*************************************************************!*\
  !*** ./node_modules/multistreamsmixer/MultiStreamsMixer.js ***!
  \*************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* WEBPACK VAR INJECTION */(function(global) {var __WEBPACK_AMD_DEFINE_ARRAY__, __WEBPACK_AMD_DEFINE_RESULT__;// Last time updated: 2019-06-21 4:09:42 AM UTC\r\n\r\n// ________________________\r\n// MultiStreamsMixer v1.2.2\r\n\r\n// Open-Sourced: https://github.com/muaz-khan/MultiStreamsMixer\r\n\r\n// --------------------------------------------------\r\n// Muaz Khan     - www.MuazKhan.com\r\n// MIT License   - www.WebRTC-Experiment.com/licence\r\n// --------------------------------------------------\r\n\r\nfunction MultiStreamsMixer(arrayOfMediaStreams, elementClass) {\r\n\r\n    var browserFakeUserAgent = 'Fake/5.0 (FakeOS) AppleWebKit/123 (KHTML, like Gecko) Fake/12.3.4567.89 Fake/123.45';\r\n\r\n    (function(that) {\r\n        if (typeof RecordRTC !== 'undefined') {\r\n            return;\r\n        }\r\n\r\n        if (!that) {\r\n            return;\r\n        }\r\n\r\n        if (typeof window !== 'undefined') {\r\n            return;\r\n        }\r\n\r\n        if (typeof global === 'undefined') {\r\n            return;\r\n        }\r\n\r\n        global.navigator = {\r\n            userAgent: browserFakeUserAgent,\r\n            getUserMedia: function() {}\r\n        };\r\n\r\n        if (!global.console) {\r\n            global.console = {};\r\n        }\r\n\r\n        if (typeof global.console.log === 'undefined' || typeof global.console.error === 'undefined') {\r\n            global.console.error = global.console.log = global.console.log || function() {\r\n                console.log(arguments);\r\n            };\r\n        }\r\n\r\n        if (typeof document === 'undefined') {\r\n            /*global document:true */\r\n            that.document = {\r\n                documentElement: {\r\n                    appendChild: function() {\r\n                        return '';\r\n                    }\r\n                }\r\n            };\r\n\r\n            document.createElement = document.captureStream = document.mozCaptureStream = function() {\r\n                var obj = {\r\n                    getContext: function() {\r\n                        return obj;\r\n                    },\r\n                    play: function() {},\r\n                    pause: function() {},\r\n                    drawImage: function() {},\r\n                    toDataURL: function() {\r\n                        return '';\r\n                    },\r\n                    style: {}\r\n                };\r\n                return obj;\r\n            };\r\n\r\n            that.HTMLVideoElement = function() {};\r\n        }\r\n\r\n        if (typeof location === 'undefined') {\r\n            /*global location:true */\r\n            that.location = {\r\n                protocol: 'file:',\r\n                href: '',\r\n                hash: ''\r\n            };\r\n        }\r\n\r\n        if (typeof screen === 'undefined') {\r\n            /*global screen:true */\r\n            that.screen = {\r\n                width: 0,\r\n                height: 0\r\n            };\r\n        }\r\n\r\n        if (typeof URL === 'undefined') {\r\n            /*global screen:true */\r\n            that.URL = {\r\n                createObjectURL: function() {\r\n                    return '';\r\n                },\r\n                revokeObjectURL: function() {\r\n                    return '';\r\n                }\r\n            };\r\n        }\r\n\r\n        /*global window:true */\r\n        that.window = global;\r\n    })(typeof global !== 'undefined' ? global : null);\r\n\r\n    // requires: chrome://flags/#enable-experimental-web-platform-features\r\n\r\n    elementClass = elementClass || 'multi-streams-mixer';\r\n\r\n    var videos = [];\r\n    var isStopDrawingFrames = false;\r\n\r\n    var canvas = document.createElement('canvas');\r\n    var context = canvas.getContext('2d');\r\n    canvas.style.opacity = 0;\r\n    canvas.style.position = 'absolute';\r\n    canvas.style.zIndex = -1;\r\n    canvas.style.top = '-1000em';\r\n    canvas.style.left = '-1000em';\r\n    canvas.className = elementClass;\r\n    (document.body || document.documentElement).appendChild(canvas);\r\n\r\n    this.disableLogs = false;\r\n    this.frameInterval = 10;\r\n\r\n    this.width = 360;\r\n    this.height = 240;\r\n\r\n    // use gain node to prevent echo\r\n    this.useGainNode = true;\r\n\r\n    var self = this;\r\n\r\n    // _____________________________\r\n    // Cross-Browser-Declarations.js\r\n\r\n    // WebAudio API representer\r\n    var AudioContext = window.AudioContext;\r\n\r\n    if (typeof AudioContext === 'undefined') {\r\n        if (typeof webkitAudioContext !== 'undefined') {\r\n            /*global AudioContext:true */\r\n            AudioContext = webkitAudioContext;\r\n        }\r\n\r\n        if (typeof mozAudioContext !== 'undefined') {\r\n            /*global AudioContext:true */\r\n            AudioContext = mozAudioContext;\r\n        }\r\n    }\r\n\r\n    /*jshint -W079 */\r\n    var URL = window.URL;\r\n\r\n    if (typeof URL === 'undefined' && typeof webkitURL !== 'undefined') {\r\n        /*global URL:true */\r\n        URL = webkitURL;\r\n    }\r\n\r\n    if (typeof navigator !== 'undefined' && typeof navigator.getUserMedia === 'undefined') { // maybe window.navigator?\r\n        if (typeof navigator.webkitGetUserMedia !== 'undefined') {\r\n            navigator.getUserMedia = navigator.webkitGetUserMedia;\r\n        }\r\n\r\n        if (typeof navigator.mozGetUserMedia !== 'undefined') {\r\n            navigator.getUserMedia = navigator.mozGetUserMedia;\r\n        }\r\n    }\r\n\r\n    var MediaStream = window.MediaStream;\r\n\r\n    if (typeof MediaStream === 'undefined' && typeof webkitMediaStream !== 'undefined') {\r\n        MediaStream = webkitMediaStream;\r\n    }\r\n\r\n    /*global MediaStream:true */\r\n    if (typeof MediaStream !== 'undefined') {\r\n        // override \"stop\" method for all browsers\r\n        if (typeof MediaStream.prototype.stop === 'undefined') {\r\n            MediaStream.prototype.stop = function() {\r\n                this.getTracks().forEach(function(track) {\r\n                    track.stop();\r\n                });\r\n            };\r\n        }\r\n    }\r\n\r\n    var Storage = {};\r\n\r\n    if (typeof AudioContext !== 'undefined') {\r\n        Storage.AudioContext = AudioContext;\r\n    } else if (typeof webkitAudioContext !== 'undefined') {\r\n        Storage.AudioContext = webkitAudioContext;\r\n    }\r\n\r\n    function setSrcObject(stream, element) {\r\n        if ('srcObject' in element) {\r\n            element.srcObject = stream;\r\n        } else if ('mozSrcObject' in element) {\r\n            element.mozSrcObject = stream;\r\n        } else {\r\n            element.srcObject = stream;\r\n        }\r\n    }\r\n\r\n    this.startDrawingFrames = function() {\r\n        drawVideosToCanvas();\r\n    };\r\n\r\n    function drawVideosToCanvas() {\r\n        if (isStopDrawingFrames) {\r\n            return;\r\n        }\r\n\r\n        var videosLength = videos.length;\r\n\r\n        var fullcanvas = false;\r\n        var remaining = [];\r\n        videos.forEach(function(video) {\r\n            if (!video.stream) {\r\n                video.stream = {};\r\n            }\r\n\r\n            if (video.stream.fullcanvas) {\r\n                fullcanvas = video;\r\n            } else {\r\n                // todo: video.stream.active or video.stream.live to fix blank frames issues?\r\n                remaining.push(video);\r\n            }\r\n        });\r\n\r\n        if (fullcanvas) {\r\n            canvas.width = fullcanvas.stream.width;\r\n            canvas.height = fullcanvas.stream.height;\r\n        } else if (remaining.length) {\r\n            canvas.width = videosLength > 1 ? remaining[0].width * 2 : remaining[0].width;\r\n\r\n            var height = 1;\r\n            if (videosLength === 3 || videosLength === 4) {\r\n                height = 2;\r\n            }\r\n            if (videosLength === 5 || videosLength === 6) {\r\n                height = 3;\r\n            }\r\n            if (videosLength === 7 || videosLength === 8) {\r\n                height = 4;\r\n            }\r\n            if (videosLength === 9 || videosLength === 10) {\r\n                height = 5;\r\n            }\r\n            canvas.height = remaining[0].height * height;\r\n        } else {\r\n            canvas.width = self.width || 360;\r\n            canvas.height = self.height || 240;\r\n        }\r\n\r\n        if (fullcanvas && fullcanvas instanceof HTMLVideoElement) {\r\n            drawImage(fullcanvas);\r\n        }\r\n\r\n        remaining.forEach(function(video, idx) {\r\n            drawImage(video, idx);\r\n        });\r\n\r\n        setTimeout(drawVideosToCanvas, self.frameInterval);\r\n    }\r\n\r\n    function drawImage(video, idx) {\r\n        if (isStopDrawingFrames) {\r\n            return;\r\n        }\r\n\r\n        var x = 0;\r\n        var y = 0;\r\n        var width = video.width;\r\n        var height = video.height;\r\n\r\n        if (idx === 1) {\r\n            x = video.width;\r\n        }\r\n\r\n        if (idx === 2) {\r\n            y = video.height;\r\n        }\r\n\r\n        if (idx === 3) {\r\n            x = video.width;\r\n            y = video.height;\r\n        }\r\n\r\n        if (idx === 4) {\r\n            y = video.height * 2;\r\n        }\r\n\r\n        if (idx === 5) {\r\n            x = video.width;\r\n            y = video.height * 2;\r\n        }\r\n\r\n        if (idx === 6) {\r\n            y = video.height * 3;\r\n        }\r\n\r\n        if (idx === 7) {\r\n            x = video.width;\r\n            y = video.height * 3;\r\n        }\r\n\r\n        if (typeof video.stream.left !== 'undefined') {\r\n            x = video.stream.left;\r\n        }\r\n\r\n        if (typeof video.stream.top !== 'undefined') {\r\n            y = video.stream.top;\r\n        }\r\n\r\n        if (typeof video.stream.width !== 'undefined') {\r\n            width = video.stream.width;\r\n        }\r\n\r\n        if (typeof video.stream.height !== 'undefined') {\r\n            height = video.stream.height;\r\n        }\r\n\r\n        context.drawImage(video, x, y, width, height);\r\n\r\n        if (typeof video.stream.onRender === 'function') {\r\n            video.stream.onRender(context, x, y, width, height, idx);\r\n        }\r\n    }\r\n\r\n    function getMixedStream() {\r\n        isStopDrawingFrames = false;\r\n        var mixedVideoStream = getMixedVideoStream();\r\n\r\n        var mixedAudioStream = getMixedAudioStream();\r\n        if (mixedAudioStream) {\r\n            mixedAudioStream.getTracks().filter(function(t) {\r\n                return t.kind === 'audio';\r\n            }).forEach(function(track) {\r\n                mixedVideoStream.addTrack(track);\r\n            });\r\n        }\r\n\r\n        var fullcanvas;\r\n        arrayOfMediaStreams.forEach(function(stream) {\r\n            if (stream.fullcanvas) {\r\n                fullcanvas = true;\r\n            }\r\n        });\r\n\r\n        // mixedVideoStream.prototype.appendStreams = appendStreams;\r\n        // mixedVideoStream.prototype.resetVideoStreams = resetVideoStreams;\r\n        // mixedVideoStream.prototype.clearRecordedData = clearRecordedData;\r\n\r\n        return mixedVideoStream;\r\n    }\r\n\r\n    function getMixedVideoStream() {\r\n        resetVideoStreams();\r\n\r\n        var capturedStream;\r\n\r\n        if ('captureStream' in canvas) {\r\n            capturedStream = canvas.captureStream();\r\n        } else if ('mozCaptureStream' in canvas) {\r\n            capturedStream = canvas.mozCaptureStream();\r\n        } else if (!self.disableLogs) {\r\n            console.error('Upgrade to latest Chrome or otherwise enable this flag: chrome://flags/#enable-experimental-web-platform-features');\r\n        }\r\n\r\n        var videoStream = new MediaStream();\r\n\r\n        capturedStream.getTracks().filter(function(t) {\r\n            return t.kind === 'video';\r\n        }).forEach(function(track) {\r\n            videoStream.addTrack(track);\r\n        });\r\n\r\n        canvas.stream = videoStream;\r\n\r\n        return videoStream;\r\n    }\r\n\r\n    function getMixedAudioStream() {\r\n        // via: @pehrsons\r\n        if (!Storage.AudioContextConstructor) {\r\n            Storage.AudioContextConstructor = new Storage.AudioContext();\r\n        }\r\n\r\n        self.audioContext = Storage.AudioContextConstructor;\r\n\r\n        self.audioSources = [];\r\n\r\n        if (self.useGainNode === true) {\r\n            self.gainNode = self.audioContext.createGain();\r\n            self.gainNode.connect(self.audioContext.destination);\r\n            self.gainNode.gain.value = 0; // don't hear self\r\n        }\r\n\r\n        var audioTracksLength = 0;\r\n        arrayOfMediaStreams.forEach(function(stream) {\r\n            if (!stream.getTracks().filter(function(t) {\r\n                    return t.kind === 'audio';\r\n                }).length) {\r\n                return;\r\n            }\r\n\r\n            audioTracksLength++;\r\n\r\n            var audioSource = self.audioContext.createMediaStreamSource(stream);\r\n\r\n            if (self.useGainNode === true) {\r\n                audioSource.connect(self.gainNode);\r\n            }\r\n\r\n            self.audioSources.push(audioSource);\r\n        });\r\n\r\n        if (!audioTracksLength) {\r\n            // because \"self.audioContext\" is not initialized\r\n            // that's why we've to ignore rest of the code\r\n            return;\r\n        }\r\n\r\n        self.audioDestination = self.audioContext.createMediaStreamDestination();\r\n        self.audioSources.forEach(function(audioSource) {\r\n            audioSource.connect(self.audioDestination);\r\n        });\r\n        return self.audioDestination.stream;\r\n    }\r\n\r\n    function getVideo(stream) {\r\n        var video = document.createElement('video');\r\n\r\n        setSrcObject(stream, video);\r\n\r\n        video.className = elementClass;\r\n\r\n        video.muted = true;\r\n        video.volume = 0;\r\n\r\n        video.width = stream.width || self.width || 360;\r\n        video.height = stream.height || self.height || 240;\r\n\r\n        video.play();\r\n\r\n        return video;\r\n    }\r\n\r\n    this.appendStreams = function(streams) {\r\n        if (!streams) {\r\n            throw 'First parameter is required.';\r\n        }\r\n\r\n        if (!(streams instanceof Array)) {\r\n            streams = [streams];\r\n        }\r\n\r\n        streams.forEach(function(stream) {\r\n            var newStream = new MediaStream();\r\n\r\n            if (stream.getTracks().filter(function(t) {\r\n                    return t.kind === 'video';\r\n                }).length) {\r\n                var video = getVideo(stream);\r\n                video.stream = stream;\r\n                videos.push(video);\r\n\r\n                newStream.addTrack(stream.getTracks().filter(function(t) {\r\n                    return t.kind === 'video';\r\n                })[0]);\r\n            }\r\n\r\n            if (stream.getTracks().filter(function(t) {\r\n                    return t.kind === 'audio';\r\n                }).length) {\r\n                var audioSource = self.audioContext.createMediaStreamSource(stream);\r\n                self.audioDestination = self.audioContext.createMediaStreamDestination();\r\n                audioSource.connect(self.audioDestination);\r\n\r\n                newStream.addTrack(self.audioDestination.stream.getTracks().filter(function(t) {\r\n                    return t.kind === 'audio';\r\n                })[0]);\r\n            }\r\n\r\n            arrayOfMediaStreams.push(newStream);\r\n        });\r\n    };\r\n\r\n    this.releaseStreams = function() {\r\n        videos = [];\r\n        isStopDrawingFrames = true;\r\n\r\n        if (self.gainNode) {\r\n            self.gainNode.disconnect();\r\n            self.gainNode = null;\r\n        }\r\n\r\n        if (self.audioSources.length) {\r\n            self.audioSources.forEach(function(source) {\r\n                source.disconnect();\r\n            });\r\n            self.audioSources = [];\r\n        }\r\n\r\n        if (self.audioDestination) {\r\n            self.audioDestination.disconnect();\r\n            self.audioDestination = null;\r\n        }\r\n\r\n        if (self.audioContext) {\r\n            self.audioContext.close();\r\n        }\r\n\r\n        self.audioContext = null;\r\n\r\n        context.clearRect(0, 0, canvas.width, canvas.height);\r\n\r\n        if (canvas.stream) {\r\n            canvas.stream.stop();\r\n            canvas.stream = null;\r\n        }\r\n    };\r\n\r\n    this.resetVideoStreams = function(streams) {\r\n        if (streams && !(streams instanceof Array)) {\r\n            streams = [streams];\r\n        }\r\n\r\n        resetVideoStreams(streams);\r\n    };\r\n\r\n    function resetVideoStreams(streams) {\r\n        videos = [];\r\n        streams = streams || arrayOfMediaStreams;\r\n\r\n        // via: @adrian-ber\r\n        streams.forEach(function(stream) {\r\n            if (!stream.getTracks().filter(function(t) {\r\n                    return t.kind === 'video';\r\n                }).length) {\r\n                return;\r\n            }\r\n\r\n            var video = getVideo(stream);\r\n            video.stream = stream;\r\n            videos.push(video);\r\n        });\r\n    }\r\n\r\n    // for debugging\r\n    this.name = 'MultiStreamsMixer';\r\n    this.toString = function() {\r\n        return this.name;\r\n    };\r\n\r\n    this.getMixedStream = getMixedStream;\r\n\r\n}\r\n\r\nif (typeof RecordRTC === 'undefined') {\r\n    if (true /* && !!module.exports*/ ) {\r\n        module.exports = MultiStreamsMixer;\r\n    }\r\n\r\n    if (true) {\r\n        !(__WEBPACK_AMD_DEFINE_ARRAY__ = [], __WEBPACK_AMD_DEFINE_RESULT__ = (function() {\r\n            return MultiStreamsMixer;\r\n        }).apply(exports, __WEBPACK_AMD_DEFINE_ARRAY__),\n\t\t\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\r\n    }\r\n}\n\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\")))\n\n//# sourceURL=webpack:///./node_modules/multistreamsmixer/MultiStreamsMixer.js?");

/***/ }),

/***/ "./node_modules/webpack/buildin/global.js":
/*!***********************************!*\
  !*** (webpack)/buildin/global.js ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("var g;\n\n// This works in non-strict mode\ng = (function() {\n\treturn this;\n})();\n\ntry {\n\t// This works if eval is allowed (see CSP)\n\tg = g || new Function(\"return this\")();\n} catch (e) {\n\t// This works if the window reference is available\n\tif (typeof window === \"object\") g = window;\n}\n\n// g can still be undefined, but nothing to do about it...\n// We return undefined, instead of nothing here, so it's\n// easier to handle this case. if(!global) { ...}\n\nmodule.exports = g;\n\n\n//# sourceURL=webpack:///(webpack)/buildin/global.js?");

/***/ })

/******/ });